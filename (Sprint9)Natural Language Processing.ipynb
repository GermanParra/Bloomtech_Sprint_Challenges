{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dCzAvNNy8YW5"
      },
      "source": [
        "# Sprint Challenge\n",
        "## *Data Science Unit 4 Sprint 1*\n",
        "\n",
        "After a week of Natural Language Processing, you've learned some cool new stuff: how to process text, how turn text into vectors, and how to model topics from documents. Apply your newly acquired skills to one of the most famous NLP datasets out there: [Yelp](https://www.yelp.com/dataset). As part of the job selection process, some of my friends have been asked to create analysis of this dataset, so I want to empower you to have a head start.  \n",
        "\n",
        "The real dataset is massive (almost 8 gigs uncompressed). I've sampled the data for you to something more manageable for the Sprint Challenge. You can analyze the full dataset as a stretch goal or after the sprint challenge. As you work on the challenge, I suggest adding notes about your findings and things you want to analyze in the future.\n",
        "\n",
        "## Challenge Objectives\n",
        "Successfully complete all these objectives to earn full credit. \n",
        "\n",
        "**Successful completion is defined as passing all the unit tests in each objective.**  \n",
        "\n",
        "Each unit test that you pass is 1 point. \n",
        "\n",
        "There are 5 total possible points in this sprint challenge. \n",
        "\n",
        "\n",
        "There are more details on each objective further down in the notebook.*\n",
        "* <a href=\"#p1\">Part 1</a>: Write a function to tokenize the yelp reviews\n",
        "* <a href=\"#p2\">Part 2</a>: Create a vector representation of those tokens\n",
        "* <a href=\"#p3\">Part 3</a>: Use your tokens in a classification model on yelp rating\n",
        "* <a href=\"#p4\">Part 4</a>: Estimate & Interpret a topic model of the Yelp reviews\n",
        "\n",
        "____\n",
        "\n",
        "# Before you submit your notebook you must first\n",
        "\n",
        "1) Restart your notebook's Kernel\n",
        "\n",
        "2) Run all cells sequentially, from top to bottom, so that cell numbers are sequential numbers (i.e. 1,2,3,4,5...)\n",
        "- Easiest way to do this is to click on the **Cell** tab at the top of your notebook and select **Run All** from the drop down menu. \n",
        "\n",
        "3) Comment out the cell that generates a pyLDAvis visual in objective 4 (see instructions in that section). \n",
        "____"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8TmxpNo8YW_"
      },
      "source": [
        "\n",
        "\n",
        "### Import Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "7bec125eb29f89460cf0c19ba9aa9a2f",
          "grade": false,
          "grade_id": "cell-395851cd95d17235",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "wpY1J1Jq8YXA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load reviews from URL\n",
        "data_url = 'https://raw.githubusercontent.com/LambdaSchool/data-science-practice-datasets/main/unit_4/unit1_nlp/review_sample.json'\n",
        "\n",
        "# Import data into a DataFrame named df\n",
        "# YOUR CODE HERE\n",
        "df = pd.read_json(data_url, lines=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "356579363f311da83f4ef7abaf3c9212",
          "grade": true,
          "grade_id": "cell-cb5006475e42b8f9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "OT6lllZo8YXB"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "assert isinstance(df, pd.DataFrame), 'df is not a DataFrame. Did you import the data into df?'\n",
        "assert df.shape[0] == 10000, 'DataFrame df has the wrong number of rows.'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1aZzwwm8YXC"
      },
      "source": [
        "## Part 1: Tokenize Function\n",
        "<a id=\"#p1\"></a>\n",
        "\n",
        "Complete the function `tokenize`. Your function should\n",
        "- accept one document at a time\n",
        "- return a list of tokens\n",
        "\n",
        "You are free to use any method you have learned this week."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CdjL9Upr8YXD"
      },
      "outputs": [],
      "source": [
        "# Optional: Consider using spaCy in your function. The spaCy library can be imported by running this cell.\n",
        "# A pre-trained model (en_core_web_sm) has been made available to you in the CodeGrade container.\n",
        "# If you DON'T need use the en_core_web_sm model, you can comment it out below.\n",
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "FJw4aXt0A8Z_",
        "outputId": "64991745-8173-4b4a-bb6a-e37a11f6df41"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-50aa4d37-85e8-4f9a-a0d2-6f90d62b2e6a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>business_id</th>\n",
              "      <th>cool</th>\n",
              "      <th>date</th>\n",
              "      <th>funny</th>\n",
              "      <th>review_id</th>\n",
              "      <th>stars</th>\n",
              "      <th>text</th>\n",
              "      <th>useful</th>\n",
              "      <th>user_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>nDuEqIyRc8YKS1q1fX0CZg</td>\n",
              "      <td>1</td>\n",
              "      <td>2015-03-31 16:50:30</td>\n",
              "      <td>0</td>\n",
              "      <td>eZs2tpEJtXPwawvHnHZIgQ</td>\n",
              "      <td>1</td>\n",
              "      <td>BEWARE!!! FAKE, FAKE, FAKE....We also own a sm...</td>\n",
              "      <td>10</td>\n",
              "      <td>n1LM36qNg4rqGXIcvVXv8w</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>eMYeEapscbKNqUDCx705hg</td>\n",
              "      <td>0</td>\n",
              "      <td>2015-12-16 05:31:03</td>\n",
              "      <td>0</td>\n",
              "      <td>DoQDWJsNbU0KL1O29l_Xug</td>\n",
              "      <td>4</td>\n",
              "      <td>Came here for lunch Togo. Service was quick. S...</td>\n",
              "      <td>0</td>\n",
              "      <td>5CgjjDAic2-FAvCtiHpytA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6Q7-wkCPc1KF75jZLOTcMw</td>\n",
              "      <td>1</td>\n",
              "      <td>2010-06-20 19:14:48</td>\n",
              "      <td>1</td>\n",
              "      <td>DDOdGU7zh56yQHmUnL1idQ</td>\n",
              "      <td>3</td>\n",
              "      <td>I've been to Vegas dozens of times and had nev...</td>\n",
              "      <td>2</td>\n",
              "      <td>BdV-cf3LScmb8kZ7iiBcMA</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>k3zrItO4l9hwfLRwHBDc9w</td>\n",
              "      <td>3</td>\n",
              "      <td>2010-07-13 00:33:45</td>\n",
              "      <td>4</td>\n",
              "      <td>LfTMUWnfGFMOfOIyJcwLVA</td>\n",
              "      <td>1</td>\n",
              "      <td>We went here on a night where they closed off ...</td>\n",
              "      <td>5</td>\n",
              "      <td>cZZnBqh4gAEy4CdNvJailQ</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6hpfRwGlOzbNv7k5eP9rsQ</td>\n",
              "      <td>1</td>\n",
              "      <td>2018-06-30 02:30:01</td>\n",
              "      <td>0</td>\n",
              "      <td>zJSUdI7bJ8PNJAg4lnl_Gg</td>\n",
              "      <td>4</td>\n",
              "      <td>3.5 to 4 stars\\n\\nNot bad for the price, $12.9...</td>\n",
              "      <td>5</td>\n",
              "      <td>n9QO4ClYAS7h9fpQwa5bhA</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-50aa4d37-85e8-4f9a-a0d2-6f90d62b2e6a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-50aa4d37-85e8-4f9a-a0d2-6f90d62b2e6a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-50aa4d37-85e8-4f9a-a0d2-6f90d62b2e6a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "              business_id  cool  ... useful                 user_id\n",
              "0  nDuEqIyRc8YKS1q1fX0CZg     1  ...     10  n1LM36qNg4rqGXIcvVXv8w\n",
              "1  eMYeEapscbKNqUDCx705hg     0  ...      0  5CgjjDAic2-FAvCtiHpytA\n",
              "2  6Q7-wkCPc1KF75jZLOTcMw     1  ...      2  BdV-cf3LScmb8kZ7iiBcMA\n",
              "3  k3zrItO4l9hwfLRwHBDc9w     3  ...      5  cZZnBqh4gAEy4CdNvJailQ\n",
              "4  6hpfRwGlOzbNv7k5eP9rsQ     1  ...      5  n9QO4ClYAS7h9fpQwa5bhA\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "4837ed2a1cc13057ba40203859d46ff6",
          "grade": false,
          "grade_id": "cell-3d570d5a1cd6cb64",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "JVf6P4_L8YXE"
      },
      "outputs": [],
      "source": [
        "def tokenize(doc):\n",
        "\n",
        "  tokens = []\n",
        "  for token in nlp(doc):\n",
        "    if (token.is_stop == False) & (token.is_punct == False) & (token.is_space == False) & (len(token.lemma_) > 2):\n",
        "      tokens.append(token.lemma_.lower())\n",
        "  return tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "2181ca9d36070260b1f75dcfd9e58965",
          "grade": true,
          "grade_id": "cell-02da164f6fbe730a",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "rBr36_pA8YXF"
      },
      "outputs": [],
      "source": [
        "'''Testing'''\n",
        "assert isinstance(tokenize(df.sample(n=1)[\"text\"].iloc[0]), list), \"Make sure your tokenizer function accepts a single document and returns a list of tokens!\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OPAZUfC8YXF"
      },
      "source": [
        "## Part 2: Vector Representation\n",
        "<a id=\"#p2\"></a>\n",
        "1. Create a vector representation of the reviews (i.e. create a doc-term matrix).\n",
        "2. Write a fake review and query for the 10 most similar reviews, print the text of the reviews. Do you notice any patterns?\n",
        "    - Given the size of the dataset, use `NearestNeighbors` model for this. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d70a0a1a96cf8406c60b17e50b255a1a",
          "grade": false,
          "grade_id": "cell-0e96491cb529202c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5zN8djMa8YXG",
        "outputId": "635e324d-4073-43fd-ad29-f89402a10dbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 4min 8s, sys: 2.29 s, total: 4min 10s\n",
            "Wall time: 4min 18s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "# Create a vector representation of the reviews \n",
        "# Name that doc-term matrix \"dtm\"\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vect = TfidfVectorizer(stop_words='english', tokenizer=tokenize, ngram_range=(1,2), max_df=0.9, min_df=0.1)\n",
        "\n",
        "dtm = vect.fit_transform(df['text'])\n",
        "\n",
        "dtm = pd.DataFrame(dtm.todense(), columns = vect.get_feature_names())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dtm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "KvCjkM4-OkQg",
        "outputId": "3df91e83-183f-4ea2-cc73-d60886f87f6a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d3e4eed8-b3e8-40b7-a4ae-f65c19c624ab\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>amazing</th>\n",
              "      <th>ask</th>\n",
              "      <th>bad</th>\n",
              "      <th>come</th>\n",
              "      <th>day</th>\n",
              "      <th>definitely</th>\n",
              "      <th>delicious</th>\n",
              "      <th>eat</th>\n",
              "      <th>experience</th>\n",
              "      <th>food</th>\n",
              "      <th>friendly</th>\n",
              "      <th>good</th>\n",
              "      <th>great</th>\n",
              "      <th>know</th>\n",
              "      <th>like</th>\n",
              "      <th>little</th>\n",
              "      <th>look</th>\n",
              "      <th>love</th>\n",
              "      <th>need</th>\n",
              "      <th>nice</th>\n",
              "      <th>order</th>\n",
              "      <th>people</th>\n",
              "      <th>place</th>\n",
              "      <th>price</th>\n",
              "      <th>recommend</th>\n",
              "      <th>restaurant</th>\n",
              "      <th>say</th>\n",
              "      <th>service</th>\n",
              "      <th>staff</th>\n",
              "      <th>tell</th>\n",
              "      <th>thing</th>\n",
              "      <th>think</th>\n",
              "      <th>time</th>\n",
              "      <th>try</th>\n",
              "      <th>wait</th>\n",
              "      <th>want</th>\n",
              "      <th>way</th>\n",
              "      <th>work</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.343826</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.424153</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.484419</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.328384</td>\n",
              "      <td>0.390375</td>\n",
              "      <td>0.454959</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.409838</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.536762</td>\n",
              "      <td>0.334525</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.389451</td>\n",
              "      <td>0.529472</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.188541</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.232589</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.768829</td>\n",
              "      <td>0.47401</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.249289</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.180073</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.446125</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.755670</td>\n",
              "      <td>0.479516</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.445987</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.421084</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.281544</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.253973</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.388179</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.392624</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.418543</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.329493</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.368254</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.518835</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.487282</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.499188</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.397121</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.648289</td>\n",
              "      <td>0.374237</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.531001</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.389218</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.704364</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.485570</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.341471</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.875724</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.275712</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.293149</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.266749</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.336390</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.320248</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.118670</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.146394</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.486716</td>\n",
              "      <td>0.102950</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.151598</td>\n",
              "      <td>0.504586</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.453359</td>\n",
              "      <td>0.134736</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows Ã— 38 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d3e4eed8-b3e8-40b7-a4ae-f65c19c624ab')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d3e4eed8-b3e8-40b7-a4ae-f65c19c624ab button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d3e4eed8-b3e8-40b7-a4ae-f65c19c624ab');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "      amazing  ask       bad      come  ...      wait  want  way      work\n",
              "0         0.0  0.0  0.000000  0.000000  ...  0.454959   0.0  0.0  0.000000\n",
              "1         0.0  0.0  0.000000  0.409838  ...  0.000000   0.0  0.0  0.000000\n",
              "2         0.0  0.0  0.000000  0.000000  ...  0.000000   0.0  0.0  0.000000\n",
              "3         0.0  0.0  0.000000  0.000000  ...  0.000000   0.0  0.0  0.000000\n",
              "4         0.0  0.0  0.445987  0.000000  ...  0.000000   0.0  0.0  0.000000\n",
              "...       ...  ...       ...       ...  ...       ...   ...  ...       ...\n",
              "9995      0.0  0.0  0.000000  0.000000  ...  0.487282   0.0  0.0  0.499188\n",
              "9996      0.0  0.0  0.000000  0.397121  ...  0.000000   0.0  0.0  0.000000\n",
              "9997      0.0  0.0  0.000000  0.389218  ...  0.000000   0.0  0.0  0.000000\n",
              "9998      0.0  0.0  0.000000  0.000000  ...  0.000000   0.0  0.0  0.000000\n",
              "9999      0.0  0.0  0.336390  0.000000  ...  0.000000   0.0  0.0  0.000000\n",
              "\n",
              "[10000 rows x 38 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "32b220e23c9aa1f602f08d1c2e879d0a",
          "grade": false,
          "grade_id": "cell-3d5bc610a8ec6b24",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSirbEmn8YXH",
        "outputId": "b190a8ed-bb08-4bb0-d671-f7b9ba4d5d87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NearestNeighbors(n_neighbors=10)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "# Create and fit a NearestNeighbors model named \"nn\"\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "# YOUR CODE HERE\n",
        "nn = NearestNeighbors(n_neighbors=10)\n",
        "nn.fit(dtm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "d270ed23df3c7d3c6cf08ab174ccaf9e",
          "grade": true,
          "grade_id": "cell-c43704dcff67e99b",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "9OwErKWJ8YXH"
      },
      "outputs": [],
      "source": [
        "'''Testing.'''\n",
        "assert nn.__module__ == 'sklearn.neighbors._unsupervised', ' nn is not a NearestNeighbors instance.'\n",
        "assert nn.n_neighbors == 10, 'nn has the wrong value for n_neighbors'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "3da2ced9f187ed0aa1a890785e2ba00e",
          "grade": false,
          "grade_id": "cell-496203e8746296ca",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VA5fX-ab8YXI",
        "outputId": "918a24d9-84b8-4e76-a393-cf4a66f4ddba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:451: UserWarning: X does not have valid feature names, but NearestNeighbors was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:598: FutureWarning: np.matrix usage is deprecated in 1.0 and will raise a TypeError in 1.2. Please convert to a numpy array with np.asarray. For more information see: https://numpy.org/doc/stable/reference/generated/numpy.matrix.html\n",
            "  FutureWarning,\n"
          ]
        }
      ],
      "source": [
        "# Create a fake review and find the 10 most similar reviews\n",
        "fake_review = [\" It was the BEST!!!!! of the best attention and experience ever, i recomend this place 1000% my family and i had an amaizing time and the service was great!!!!, averyone should come here at least once in life, all people was good and happy\"]\n",
        "fake_review_sparse = vect.transform(fake_review)\n",
        "# YOUR CODE HERE\n",
        "nn_dist, nn_indexes = nn.kneighbors(fake_review_sparse.todense())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['text'][nn_indexes[0][0]], nn_dist[0][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kPWvLSh7Uh5P",
        "outputId": "e107fef2-9f77-43a3-8623-57408d4a435f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('Mon amie gabi is super fancy and the service is good the free bread was beyond your average olive garden.  Worth it just for the conservatory seating experience. All in all good people good times and the steak rocks.',\n",
              " 0.4427737068037744)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fake_review[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "VLPehTUDVTyc",
        "outputId": "01a3de29-4a9b-4415-f3a7-7bc61c023c9a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' It was the BEST!!!!! of the best attention and experience ever, i recomend this place 1000% my family and i had an amaizing time and the service was great!!!!, averyone should come here at least once in life, all people was good and happy'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFjbL1fs8YXI"
      },
      "source": [
        "## Part 3: Classification\n",
        "<a id=\"#p3\"></a>\n",
        "Your goal in this section will be to predict `stars` from the review dataset. \n",
        "\n",
        "1. Create a pipeline object with a sklearn `CountVectorizer` or `TfidfVector` and any sklearn classifier.\n",
        "    - Use that pipeline to train a model to predict the `stars` feature (i.e. the labels). \n",
        "    - Use that Pipeline to predict a star rating for your fake review from Part 2. \n",
        "\n",
        "\n",
        "\n",
        "2. Create a parameter dict including `one parameter for the vectorizer` and `one parameter for the model`. \n",
        "    - Include 2 possible values for each parameter\n",
        "    - **Use `n_jobs` = 1** \n",
        "    - Due to limited computational resources on CodeGrader `DO NOT INCLUDE ADDITIONAL PARAMETERS OR VALUES PLEASE.`\n",
        "    \n",
        "    \n",
        "3. Train the entire pipeline with a GridSearch\n",
        "    - Name your GridSearch object as `gs`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "def clean_text(doc):\n",
        "  doc = doc.lower()\n",
        "  doc = re.sub('[^a-z]+', ' ', doc)\n",
        "  return doc.strip()"
      ],
      "metadata": {
        "id": "5Q47w8443j4M"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "deletable": false,
        "jupyter": {
          "outputs_hidden": true
        },
        "nbgrader": {
          "cell_type": "code",
          "checksum": "e1d18da8521d51d8bfc4b5b9d005fa34",
          "grade": false,
          "grade_id": "cell-e2beb0252d274bba",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eQmYM-qh8YXJ",
        "outputId": "abda0b53-c67e-4fb0-efa6-9ba881e72e01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 2 folds for each of 1 candidates, totalling 2 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neighbors/_base.py:504: UserWarning: cannot use tree with sparse input: using brute force\n",
            "  warnings.warn(\"cannot use tree with sparse input: using brute force\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4854"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "X = df['text'].apply(clean_text)\n",
        "y = df['stars']\n",
        "\n",
        "vect = TfidfVectorizer(stop_words='english', ngram_range=(1,2), max_df=0.9)\n",
        "clf = KNeighborsClassifier(algorithm ='ball_tree')\n",
        "\n",
        "pipe = Pipeline([\n",
        "                 ('vect', vect),\n",
        "                 ('clf', clf)\n",
        "                 ])\n",
        "\n",
        "params = {\n",
        "    'vect__max_features':[1000],\n",
        "    'clf__leaf_size':[35]\n",
        "}\n",
        "\n",
        "# Name the gridsearch instance \"gs\"\n",
        "gs = GridSearchCV(pipe, params, cv=2, n_jobs=-1, verbose=1)\n",
        "                 \n",
        "\n",
        "gs.fit(X, y)\n",
        "\n",
        "gs.best_score_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gs.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8q09iYoj4uXv",
        "outputId": "7cb2a74c-5435-4096-c526-5f9bc5353128"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'clf__leaf_size': 35, 'vect__max_features': 1000}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gs.predict(fake_review)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S3n07sxAl1kF",
        "outputId": "fa691c5f-4888-451c-c3e7-12d121ee31c5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "b9e2378efb868f104a4eb39e4f25563c",
          "grade": true,
          "grade_id": "cell-d07134c6fe5d056e",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "VUNAiH5g8YXJ"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "prediction = gs.predict([\"I wish dogs knew how to speak English.\"])[0]\n",
        "assert prediction in df.stars.values, 'You gs object should be able to accept raw text within a list. Did you include a vectorizer in your pipeline?'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yzoMKy9M8YXJ"
      },
      "source": [
        "## Part 4: Topic Modeling\n",
        "\n",
        "Let's find out what those yelp reviews are saying! :D\n",
        "\n",
        "1. Estimate a LDA topic model of the review text\n",
        "    - Set num_topics to `5`\n",
        "    - Name your LDA model `lda`\n",
        "2. Create 1-2 visualizations of the results\n",
        "    - You can use the most important 3 words of a topic in relevant visualizations. Refer to yesterday's notebook to extract. \n",
        "3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model\n",
        "\n",
        "When you instantiate your LDA model, it should look like this: \n",
        "\n",
        "```python\n",
        "lda = LdaModel(corpus=corpus,\n",
        "               id2word=id2word,\n",
        "               random_state=723812,\n",
        "               num_topics = num_topics,\n",
        "               passes=1\n",
        "              )\n",
        "\n",
        "```\n",
        "\n",
        "__*Note*__: You can pass the DataFrame column of text reviews to gensim. You do not have to use a generator."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr3MHERT8YXK"
      },
      "source": [
        "## Note about  pyLDAvis\n",
        "\n",
        "**pyLDAvis** is the Topic modeling package that we used in class to visualize the topics that LDA generates for us.\n",
        "\n",
        "You are welcomed to use pyLDAvis if you'd like for your visualization. However, **you MUST comment out the code that imports the package and the cell that generates the visualization before you submit your notebook to CodeGrade.** \n",
        "\n",
        "Although you should leave the print out of the visualization for graders to see (i.e. comment out the cell after you run it to create the viz). "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "hdb9fZ1C8YXK"
      },
      "outputs": [],
      "source": [
        "from gensim import corpora\n",
        "# Due to limited computationalresources on CodeGrader, use the non-multicore version of LDA \n",
        "from gensim.models.ldamodel import LdaModel\n",
        "import gensim\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V0H3MA3b8YXK"
      },
      "source": [
        "### 1. Estimate a LDA topic model of the review tex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "9514841e71735eaa255bccc53b257896",
          "grade": false,
          "grade_id": "cell-66331a185ff52f15",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "id": "rN2mAPC78YXL"
      },
      "outputs": [],
      "source": [
        "# Remember to read the LDA docs for more information on the various class attirbutes and methods available to you\n",
        "# in the LDA model: https://radimrehurek.com/gensim/models/ldamodel.html\n",
        "\n",
        "# don't change this value \n",
        "num_topics = 5\n",
        "\n",
        "# use tokenize function you created earlier to create tokens \n",
        "tokens = df['text'].apply(tokenize)\n",
        "# create a id2word object (hint: use corpora.Dictionary)\n",
        "id2word = corpora.Dictionary(tokens)\n",
        "# create a corpus object (hint: id2word.doc2bow)\n",
        "corpus = [id2word.doc2bow(doc_tokens) for doc_tokens in tokens]\n",
        "# instantiate an lda model\n",
        "\n",
        "lda = LdaModel(corpus=corpus,\n",
        "               id2word=id2word,\n",
        "               num_topics=5,\n",
        "               random_state=42,\n",
        "               passes=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3rvJ4p3w8YXL"
      },
      "source": [
        "#### Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "6479db0fa59c99d3ae3201c1f10ebca1",
          "grade": true,
          "grade_id": "cell-5a3c181311134fa9",
          "locked": true,
          "points": 1,
          "schema_version": 3,
          "solution": false,
          "task": false
        },
        "id": "cV0YaYSp8YXL"
      },
      "outputs": [],
      "source": [
        "# Visible Testing\n",
        "assert lda.get_topics().shape[0] == 5, 'Did your model complete its training? Did you set num_topics to 5?'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tvgvbjzj8YXL"
      },
      "source": [
        "#### 2. Create 1-2 visualizations of the results"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install pyLDAvis==2.1.2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r8VYesTKWIK",
        "outputId": "8a24c2c4-5803-436d-f347-ee5eefbd8e72"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyLDAvis==2.1.2 in /usr/local/lib/python3.7/dist-packages (2.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.21.5)\n",
            "Requirement already satisfied: pandas>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.3.5)\n",
            "Requirement already satisfied: scipy>=0.18.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.4.1)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (3.6.4)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.17)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (0.16.0)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (2.8.1)\n",
            "Requirement already satisfied: jinja2>=2.7.2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (2.11.3)\n",
            "Requirement already satisfied: wheel>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (0.37.1)\n",
            "Requirement already satisfied: joblib>=0.8.4 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis==2.1.2) (1.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2>=2.7.2->pyLDAvis==2.1.2) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->pyLDAvis==2.1.2) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.17.0->pyLDAvis==2.1.2) (2018.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=0.17.0->pyLDAvis==2.1.2) (1.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from numexpr->pyLDAvis==2.1.2) (21.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->numexpr->pyLDAvis==2.1.2) (3.0.7)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (8.12.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (1.11.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (57.4.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest->pyLDAvis==2.1.2) (21.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "deletable": false,
        "nbgrader": {
          "cell_type": "code",
          "checksum": "189591ed7b9e6e6146d59761fb418268",
          "grade": false,
          "grade_id": "cell-9b043e992fbd218c",
          "locked": false,
          "schema_version": 3,
          "solution": true,
          "task": false
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 931
        },
        "id": "BB4PwNeD8YXM",
        "outputId": "6161618a-ae68-4a4c-fc92-5014447e1b4d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n",
            "/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py:232: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  head(R).drop('saliency', 1)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el35421404382511085609713984924\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el35421404382511085609713984924_data = {\"mdsDat\": {\"x\": [-0.044363083560338454, -0.14622990684298437, 0.09913301628364388, 0.0011940620667252092, 0.09026591205295373], \"y\": [-0.014928103853332484, 0.014114684410800432, -0.0651767135266967, -0.02140111530808768, 0.0873912482773164], \"topics\": [1, 2, 3, 4, 5], \"cluster\": [1, 1, 1, 1, 1], \"Freq\": [32.20068693132326, 28.58773164179057, 21.054543076994868, 10.725057968461254, 7.431980381430043]}, \"tinfo\": {\"Term\": [\"room\", \"car\", \"food\", \"time\", \"tell\", \"hotel\", \"call\", \"work\", \"hair\", \"say\", \"chicken\", \"come\", \"know\", \"check\", \"day\", \"customer\", \"coffee\", \"ask\", \"year\", \"great\", \"service\", \"appointment\", \"place\", \"drink\", \"stay\", \"flavor\", \"help\", \"cheese\", \"need\", \"meat\", \"cajun\", \"layout\", \"hibachi\", \"bowling\", \"ship\", \"omelet\", \"grub\", \"josh\", \"ikea\", \"peoria\", \"rim\", \"rise\", \"skinny\", \"quesadilla\", \"cannoli\", \"smokey\", \"officially\", \"appliance\", \"alley\", \"knife\", \"maze\", \"dang\", \"yellowtail\", \"fog\", \"pedicure\", \"bust\", \"festival\", \"bum\", \"bitterness\", \"denny\", \"brewery\", \"fianc\\u00e9\", \"chai\", \"freezer\", \"gel\", \"nail\", \"izakaya\", \"waitress\", \"hall\", \"drink\", \"table\", \"sushi\", \"seat\", \"manicure\", \"order\", \"food\", \"refill\", \"breakfast\", \"bartender\", \"service\", \"server\", \"great\", \"beer\", \"wait\", \"price\", \"come\", \"place\", \"lot\", \"quick\", \"sit\", \"roll\", \"eat\", \"ask\", \"minute\", \"good\", \"waiter\", \"nice\", \"friendly\", \"menu\", \"time\", \"get\", \"like\", \"restaurant\", \"love\", \"try\", \"want\", \"staff\", \"bad\", \"experience\", \"definitely\", \"look\", \"take\", \"margaritas\", \"enchilada\", \"ipad\", \"soo\", \"margarita\", \"uptown\", \"jalape\\u00f1os\", \"rum\", \"asia\", \"heartbeat\", \"gooey\", \"tartar\", \"pearl\", \"balsamic\", \"tai\", \"specially\", \"mince\", \"ink\", \"nacho\", \"4.50\", \"schwartz\", \"jamba\", \"copa\", \"hahaha\", \"brussel\", \"ponzu\", \"mex\", \"rubber\", \"asado\", \"horchata\", \"gyro\", \"freshness\", \"pork\", \"raman\", \"dumpling\", \"zucchini\", \"salsa\", \"poutine\", \"pudding\", \"pho\", \"meat\", \"flavorful\", \"lemon\", \"broth\", \"dessert\", \"flavor\", \"cookie\", \"tasty\", \"chocolate\", \"soup\", \"beef\", \"bbq\", \"crispy\", \"cream\", \"dish\", \"tender\", \"cheese\", \"chicken\", \"green\", \"rib\", \"salad\", \"sauce\", \"butter\", \"fresh\", \"fry\", \"noodle\", \"taste\", \"taco\", \"good\", \"delicious\", \"ice\", \"bit\", \"steak\", \"bread\", \"little\", \"restaurant\", \"try\", \"food\", \"place\", \"burger\", \"love\", \"like\", \"menu\", \"great\", \"come\", \"order\", \"definitely\", \"time\", \"eat\", \"nice\", \"get\", \"amazing\", \"service\", \"stylist\", \"piss\", \"kevin\", \"physician\", \"uneven\", \"hair\", \"laser\", \"curly\", \"navigation\", \"verify\", \"lawyer\", \"talented\", \"hakka\", \"pregnancy\", \"horribly\", \"a.m.\", \"secure\", \"j'ai\", \"cola\", \"coca\", \"dash\", \"curl\", \"disposal\", \"reality\", \"gumbo\", \"quit\", \"haircut\", \"running\", \"instruct\", \"nordstrom\", \"car\", \"surgery\", \"rep\", \"yoga\", \"availability\", \"instructor\", \"appointment\", \"tire\", \"dr.\", \"weekly\", \"dealership\", \"class\", \"call\", \"mechanic\", \"dentist\", \"office\", \"repair\", \"vehicle\", \"email\", \"patient\", \"wash\", \"phone\", \"warranty\", \"test\", \"schedule\", \"month\", \"purchase\", \"color\", \"year\", \"professional\", \"work\", \"company\", \"salon\", \"fix\", \"answer\", \"tell\", \"guy\", \"day\", \"week\", \"care\", \"say\", \"time\", \"customer\", \"know\", \"store\", \"need\", \"new\", \"look\", \"find\", \"feel\", \"want\", \"get\", \"people\", \"like\", \"recommend\", \"service\", \"take\", \"place\", \"great\", \"good\", \"staff\", \"come\", \"try\", \"ask\", \"contractor\", \"promotion\", \"harness\", \"scorpion\", \"earl\", \"mojito\", \"bumper\", \"macaron\", \"desperate\", \"cesar\", \"alex\", \"arrogant\", \"pico\", \"lil\", \"spider\", \"hollandaise\", \"accent\", \"medicine\", \"calzone\", \"baker\", \"froyo\", \"pinball\", \"eliminate\", \"pharmacy\", \"death\", \"croque\", \"tops\", \"mortgage\", \"lox\", \"rick\", \"balloon\", \"photography\", \"mongolian\", \"hills\", \"professionally\", \"pregnant\", \"pad\", \"owe\", \"pest\", \"shawarma\", \"thai\", \"contract\", \"bomb\", \"artist\", \"dog\", \"groom\", \"bagel\", \"sum\", \"coffee\", \"donut\", \"pet\", \"time\", \"review\", \"hurt\", \"card\", \"come\", \"place\", \"say\", \"tip\", \"great\", \"tell\", \"coupon\", \"service\", \"see\", \"like\", \"home\", \"good\", \"day\", \"food\", \"experience\", \"order\", \"pay\", \"job\", \"want\", \"thing\", \"think\", \"get\", \"look\", \"location\", \"staff\", \"know\", \"recommend\", \"amazing\", \"ask\", \"love\", \"try\", \"price\", \"take\", \"nice\", \"yuk\", \"cirque\", \"dunkin\", \"unorganized\", \"dedicated\", \"pakora\", \"humor\", \"biryani\", \"capacity\", \"nite\", \"tilapia\", \"silk\", \"del\", \"und\", \"resume\", \"rug\", \"cr\\u00eape\", \"2006\", \"lash\", \"bi\\u00e8re\", \"recline\", \"angle\", \"perspective\", \"awake\", \"avec\", \"errand\", \"embassy\", \"blind\", \"tr\\u00e8s\", \"c'est\", \"est\", \"canal\", \"disgust\", \"crown\", \"tissue\", \"asada\", \"sleep\", \"tan\", \"unhappy\", \"les\", \"bride\", \"suite\", \"des\", \"shower\", \"room\", \"sont\", \"hotel\", \"bed\", \"dental\", \"mais\", \"carne\", \"une\", \"fly\", \"pool\", \"elevator\", \"floor\", \"procedure\", \"check\", \"help\", \"pour\", \"stay\", \"book\", \"know\", \"get\", \"people\", \"bad\", \"service\", \"come\", \"home\", \"care\", \"look\", \"ask\", \"experience\", \"star\", \"like\", \"way\", \"need\", \"work\", \"take\", \"time\", \"place\", \"tell\", \"good\", \"customer\", \"food\"], \"Freq\": [1045.0, 713.0, 4799.0, 4151.0, 1462.0, 459.0, 819.0, 1457.0, 426.0, 1454.0, 1426.0, 3734.0, 1608.0, 938.0, 1524.0, 1095.0, 575.0, 1401.0, 958.0, 4141.0, 3615.0, 400.0, 5149.0, 1357.0, 605.0, 766.0, 593.0, 877.0, 1347.0, 689.0, 31.594311200435776, 29.505236148471113, 31.76542694533946, 27.454764258002683, 26.774927708232006, 25.743793286944225, 22.74910569288669, 21.05962852881003, 19.089537526918054, 22.025235920488033, 17.131821780863717, 17.058830082179743, 16.74109713677929, 33.227491994831425, 15.695774849304696, 21.474011456410786, 14.911690449703555, 14.386739400791528, 13.216706635325474, 19.896785155402497, 19.338743145235487, 12.504829172916045, 28.70626237028838, 12.522614510102033, 134.18165899269653, 15.508857315711024, 14.164016985364968, 13.606999494090964, 14.005851470065537, 14.189564468400146, 34.97979891775945, 31.470678520759712, 30.6269278280115, 21.73560898038536, 89.56005394347747, 307.44556804774777, 19.75258661868456, 359.5161869008793, 26.178511194089836, 979.7202049184741, 717.2595187815961, 378.8640763469581, 395.9912794678935, 56.71731707744706, 1871.1255759138182, 2545.1705103924323, 90.0492567199429, 301.4813629467593, 169.97746556397144, 1814.550217417373, 497.1950805394311, 1981.6282345747818, 365.6302137376236, 842.8449425676121, 869.1024627051519, 1636.2008318948795, 2081.107309704381, 548.7443424846858, 260.1506502203895, 406.5206785967991, 320.07389226183204, 716.95724685858, 674.4666233470099, 517.6851032034399, 2257.1386851568354, 207.6120959602292, 757.8505532869495, 638.6826714472163, 598.2043761996366, 1432.8302929911733, 1050.763128809462, 1256.7425123902174, 689.039753037111, 791.0667211845475, 828.1126850026446, 663.2893819614778, 616.9722303339817, 512.4895070498247, 547.4161930433909, 546.8639340705289, 574.3949744816082, 529.5487611474076, 57.28334919297633, 38.83955660709162, 29.415046704026665, 35.11142518628209, 82.3808416315517, 17.787716144745403, 17.65712484092427, 18.626486390578393, 23.99645953628493, 18.39161519111621, 18.101009136828218, 17.56874807281918, 23.083396516568186, 27.689966326464678, 12.857584995453871, 12.452078893990869, 12.164645975820477, 13.919326194862055, 20.473206280504293, 11.090550239919645, 10.618148122243289, 11.180278054489715, 10.305698671935835, 10.207295976234333, 20.166364017932594, 13.47534729614218, 13.727069622191609, 12.670897178125207, 11.441556250393909, 13.516141804173296, 51.67220390608838, 26.571914771767123, 343.04999249036615, 159.33603833111502, 63.998079687292794, 37.07632567311452, 196.2198315066793, 59.41740739825669, 55.23341654176028, 105.0605501945255, 572.096843452833, 157.0922960443337, 104.75634695633981, 127.53455281783106, 437.8939194622744, 603.9737668282519, 133.55628220941617, 420.82690924908337, 251.22427375783693, 414.33176371588866, 373.8071969364567, 200.0059781043569, 170.34692314556295, 432.92178466271065, 654.1797965841622, 163.76404926773068, 629.3721001632634, 975.35925781403, 279.053741790848, 173.701885875375, 537.7327489781131, 631.1455876192008, 171.13535878064607, 626.0397475064583, 586.5225115110318, 242.9416080176755, 730.892715472133, 354.1750629036397, 2832.264764889625, 737.2544395005966, 337.1686300269148, 513.250486244008, 322.2361116152438, 333.5922021050144, 712.4469953538737, 807.1407561226316, 1065.4328062584777, 1676.220372438243, 1749.7252467695384, 427.027587750565, 898.5270763094455, 1202.946324258178, 609.9679273825618, 1090.6442044292148, 958.8723836023837, 899.8937085883468, 568.9646072859883, 789.5506869401726, 554.5651126735298, 575.0019067243617, 632.5580707295554, 516.6791130331562, 611.8561995884922, 77.63915416462532, 31.486949560214118, 22.994702852883552, 22.60490635299157, 16.168404349498505, 405.9155126964542, 28.286249126279433, 20.52880815797404, 17.397562452285918, 13.367588617117566, 14.52967977464167, 27.968065794327686, 13.743477914114393, 15.001026683995676, 18.865691908192858, 12.984244211669687, 12.464305555721564, 18.262350677988408, 12.033869570070566, 11.648863877313063, 13.588607325898577, 13.50278358324343, 12.34014374367211, 10.748787267351714, 11.124683096277675, 21.68731836679317, 84.5261879966336, 12.573057821175155, 14.826711268519292, 15.212028316565492, 646.1586353213529, 32.455805932411565, 25.509119620476426, 34.27616458645394, 17.33759643976064, 48.70184588851141, 347.2997573370213, 127.37023757824439, 165.22061282188542, 41.83517135384239, 72.14310770545718, 193.1690712164941, 624.3204627769911, 52.610891942321295, 62.130078387244325, 262.28346563364187, 165.11711222745518, 85.13031305833407, 107.92268142283807, 140.33853807666907, 81.35898039221595, 282.0920836069119, 62.7312423077376, 77.2975487863406, 122.0205934240554, 293.7727057236721, 200.83184275855777, 136.27867413378576, 537.723084241429, 237.17997881235667, 747.2246839619099, 248.38665576350752, 167.10949576715777, 233.20910006582912, 156.19478733903614, 663.7046162674105, 349.7206470402009, 653.9310387619935, 332.0549198661881, 332.53155908968, 605.0690038434118, 1204.8390745273475, 451.9334585779153, 582.9774040609881, 362.5710012200316, 511.883771248634, 450.5687789125454, 618.5391539087042, 528.0971225282701, 426.3563052866638, 521.442474413275, 663.4488201163829, 466.0194331157562, 730.9417981193378, 452.350712404805, 663.8714620590379, 432.6849723978616, 620.0595315399802, 572.1197934027323, 627.1386331193099, 410.85469623005235, 489.9568341419672, 408.4790016703174, 382.70225584938265, 20.67555421295445, 18.08498876647717, 21.925324298847208, 17.085689394446753, 16.43761067437228, 12.42559401776677, 12.616100410418504, 14.309336442318234, 11.320369607342462, 10.508508094423817, 16.114936996611746, 9.494442791117958, 14.760304398276164, 11.785523800528766, 9.012632745757863, 17.96317759721433, 8.976086880999725, 8.904607055849022, 8.377756113961958, 11.447503018634377, 10.290027766972694, 7.925217660356104, 7.775215910431897, 13.950125772667628, 16.14262478141596, 7.296052197972894, 7.3226796750430605, 8.081543546995327, 7.052503060608771, 7.149390343470378, 27.419211960685676, 18.96145067417162, 14.552726607462816, 14.229489502580003, 11.602469138242276, 15.22369880596244, 70.33662708316794, 14.136889293806279, 18.44561170096183, 28.895322995731572, 128.1343654538396, 30.052179364845557, 51.30566783936791, 31.15520108577214, 182.93709086935326, 21.848409842005243, 42.463316522907895, 32.36682671184329, 208.40336978029814, 75.63265865997221, 46.091177920102744, 586.7858110909324, 201.2386352903166, 36.27033854366432, 76.8243439938733, 469.1135508497413, 559.4226431225828, 248.35801299255652, 85.19174842842332, 456.70355533403693, 241.12144376270157, 38.74924338194783, 344.6241832589573, 127.64838072405381, 341.41239430642275, 140.16640045085563, 435.98983300027936, 201.95854431383043, 360.2077315810712, 183.49741840305282, 285.73112481684154, 137.17206774891613, 107.73462434475924, 196.92709574754966, 159.45718684789506, 174.36599496020338, 239.25598831923696, 200.78999941984904, 141.7985349556208, 174.97670855403481, 174.29773302853843, 163.8709536612888, 156.20660571617, 157.2548345191579, 174.48380298715648, 174.49224995755662, 160.7101659544055, 147.2492442838208, 149.2052976254986, 49.909985861877644, 25.892413202634206, 18.684165942453934, 15.572276595828445, 12.650894314322223, 15.30777340005607, 11.893799197538662, 11.29211142884283, 10.684793686849925, 9.017166698323992, 9.336573918361104, 8.692799691108537, 15.469179631230993, 7.668398688897068, 12.3436713648534, 10.820660088304628, 8.102735655049884, 8.655792915411936, 33.972193445993575, 6.6559191090284235, 10.418522798333202, 8.926936487406557, 8.46163210624631, 6.750169924283509, 13.42083261554921, 7.410193603041656, 8.019496284655315, 17.659537445871887, 19.391558663013516, 7.6595566385523695, 24.413781773837442, 27.59601401944439, 15.279247450534672, 14.246780645661893, 11.525918255828573, 37.5629809871707, 58.584469181906485, 32.290302970332235, 13.237160629041425, 32.237163564563595, 12.274706753837824, 49.525188356791496, 24.130700895884033, 64.39687246919166, 492.4157378934171, 14.172107155644136, 209.55632058601776, 78.08051129547867, 35.469942599914134, 17.074717052580095, 34.9203858835606, 20.563222304946294, 45.35458939747294, 95.04146681627846, 33.10158888578629, 87.369430266951, 31.49956533018813, 169.2005572206795, 118.55824443542753, 37.83396572300568, 115.1437875759347, 60.9428889751858, 148.23674192313322, 182.39729660896685, 132.7491055301524, 112.45040999021509, 180.6352194914242, 180.5529280142404, 93.11384757891383, 85.11176793535009, 125.19833372783663, 111.28835234931739, 108.52740688603761, 96.7779825843631, 150.48314020914233, 98.96459289038599, 104.56507799823282, 106.93387235460999, 101.81730671345815, 137.1171532071411, 139.6440786955564, 99.10204867818648, 121.90259203880596, 87.62793765388443, 94.63706790434368], \"Total\": [1045.0, 713.0, 4799.0, 4151.0, 1462.0, 459.0, 819.0, 1457.0, 426.0, 1454.0, 1426.0, 3734.0, 1608.0, 938.0, 1524.0, 1095.0, 575.0, 1401.0, 958.0, 4141.0, 3615.0, 400.0, 5149.0, 1357.0, 605.0, 766.0, 593.0, 877.0, 1347.0, 689.0, 32.39017144175847, 30.30021627418359, 32.67388991424103, 28.28279141488879, 27.68386532271184, 26.665494285434168, 23.60956384253176, 21.876911962047696, 19.89474763439756, 23.028543489325987, 17.920481642789277, 17.853346350521125, 17.53955371434929, 34.83424124516183, 16.474288567437412, 22.64547022017397, 15.734464415998975, 15.196838200570966, 14.00844573630097, 21.09772685011911, 20.528729249907126, 13.28205267794828, 30.51730846977297, 13.326587067502459, 142.8594621989642, 16.51539644943507, 15.09544163520644, 14.507622828335682, 14.948596337839582, 15.150156131693803, 37.72806587486604, 33.93291311222552, 33.15385631966588, 23.373079892829498, 101.64856625437197, 370.76004444470266, 21.31917605335251, 452.38538306691686, 28.679024877715772, 1357.7235932417318, 1072.0490836166875, 536.4046115649282, 570.0760363851739, 67.65762965467816, 3362.2405966665006, 4799.613268050696, 113.93721308607257, 453.6548962160873, 237.63239555427882, 3615.537281815285, 824.8247517070041, 4141.695806278145, 609.8034824542231, 1651.4007383480016, 1715.4551662173885, 3734.696528503212, 5149.958809832038, 1046.501921682258, 426.86061041230647, 738.4366453100606, 555.4542305983866, 1493.8988777836835, 1401.2575940878503, 1018.6728154143724, 6274.434508204856, 332.8367004808596, 1729.6189693253443, 1393.100982460124, 1291.8592526168122, 4151.123018756766, 2768.4233045836045, 3682.5261692832983, 1685.948575799883, 2226.2216631294846, 2532.0732865925097, 1719.8298598045687, 1567.0222210201562, 1145.0143018967829, 1371.0748388815225, 1399.9071087827613, 1913.1129073314712, 1395.7721018602015, 58.53028962655386, 39.779704017397144, 30.17952137167524, 36.151138262100595, 85.6881331361192, 18.521750568716527, 18.411018634573747, 19.438812199515397, 25.081811227154837, 19.239811729706542, 19.004929542388414, 18.450161306675398, 24.318624664531026, 29.22205442415933, 13.587481287538996, 13.203961059239507, 12.948270483325455, 14.834900045734663, 21.840192702860996, 11.850544555879546, 11.35416951832001, 11.966011047751856, 11.036109275620857, 10.94540242941261, 21.660617921997286, 14.495051057656198, 14.842616345955351, 13.707168141984095, 12.377724274477776, 14.65793023188171, 56.60639857657785, 28.98797412875656, 387.8144203627678, 177.6070705545028, 70.47222432771422, 40.64877398050556, 226.28338468547176, 66.4945998883834, 61.81994039700951, 120.11921801245897, 689.3088581421542, 183.5224553149782, 120.71641395396284, 148.48003021125405, 540.7250231568547, 766.0921991852755, 158.2480813882785, 539.8593654257467, 313.3556381592002, 539.3621876455045, 483.6333203888135, 248.14691747329255, 209.52153621535018, 573.2548117206321, 906.1097475168627, 201.69561928130082, 877.623255852712, 1426.8775441461607, 361.7465669407471, 216.39020569428308, 769.9505768171005, 935.2255466685407, 214.51896347294303, 941.6986201411304, 874.6458990458268, 320.0611941451784, 1206.8752539146053, 509.7442762700085, 6274.434508204856, 1244.2023766449647, 497.4542433190987, 863.6478487215244, 478.26305249284627, 501.2384465097452, 1416.7375140078361, 1685.948575799883, 2532.0732865925097, 4799.613268050696, 5149.958809832038, 721.5671783152095, 2226.2216631294846, 3682.5261692832983, 1291.8592526168122, 4141.695806278145, 3734.696528503212, 3362.2405966665006, 1399.9071087827613, 4151.123018756766, 1493.8988777836835, 1729.6189693253443, 2768.4233045836045, 1349.6294360044747, 3615.537281815285, 80.17248736124372, 32.72746173580155, 23.957889865386285, 23.631041189808315, 16.953302707917423, 426.13999671810353, 29.695811408220962, 21.59223154315125, 18.34605136482636, 14.112314103114437, 15.34859444396933, 29.57329811926031, 14.574561027387901, 15.921961570266484, 20.030738976226584, 13.788153098455597, 13.24610509905641, 19.429234826529573, 12.808900242677833, 12.407269758873955, 14.486644658502275, 14.401288767605626, 13.174154044391226, 11.49400357073091, 11.899472208272389, 23.23796005632481, 90.64381122729958, 13.48906391845712, 15.909994170043111, 16.329872539110088, 713.7393902816531, 35.009255191319205, 27.46917259384408, 37.064509618406234, 18.627586146785077, 53.01199903785437, 400.1143380032499, 147.04214716585992, 193.39069395875606, 46.42464938444533, 81.93140676246036, 229.32421715151986, 819.0529977206612, 59.932345205248396, 72.19920895330615, 335.59854633115873, 206.36674850735395, 102.1468840829034, 132.68287193377296, 178.13922437865318, 98.1121291627736, 386.1138958196119, 74.88562209445811, 96.43667979016914, 162.11703233992378, 453.07772944330424, 293.36617468411356, 188.6386968560616, 958.1235579088691, 367.87912736251, 1457.0871373177804, 388.98169617931546, 244.56502774159588, 371.19055128835237, 230.41439233313028, 1462.2093263597699, 647.1298417861088, 1524.5104584600167, 636.4347710387077, 637.832865034293, 1454.6851291134763, 4151.123018756766, 1095.0139647660694, 1608.1522101377473, 799.5206587574623, 1347.954625539483, 1128.7494629114672, 1913.1129073314712, 1567.172205816937, 1152.4377106729187, 1719.8298598045687, 2768.4233045836045, 1429.9127364795486, 3682.5261692832983, 1385.7729590142355, 3615.537281815285, 1395.7721018602015, 5149.958809832038, 4141.695806278145, 6274.434508204856, 1567.0222210201562, 3734.696528503212, 2532.0732865925097, 1401.2575940878503, 21.553163025407773, 18.89940148319097, 22.980549435288758, 18.161938087400454, 17.480189132902968, 13.240808322810755, 13.499950212526795, 15.341010765333644, 12.152717325826911, 11.319161949318516, 17.36813771039344, 10.316267000610601, 16.05571140730545, 12.832805698163929, 9.816627348933148, 19.582378546671883, 9.799660820026297, 9.749745822886034, 9.175494948361596, 12.55207993655689, 11.331624622892997, 8.734489475321178, 8.580557991008595, 15.40158255602202, 17.89851931496523, 8.108402306827402, 8.143117623930973, 8.988920498255572, 7.850385812943283, 7.965522986124702, 30.735427015815752, 21.24196866485144, 16.305747409368085, 15.985363570779015, 12.991249799304489, 17.171353590478887, 85.5457411912172, 16.00404949604613, 21.283201312142424, 35.785737836670236, 193.40838988509623, 38.75184926553411, 72.72217771236728, 41.09244232861697, 341.82533337516867, 27.869355262087105, 64.79884486422308, 45.99722652465614, 575.5024012291901, 150.60088761451078, 84.99140990451389, 4151.123018756766, 874.0664319801091, 65.19829418258524, 210.74456173069882, 3734.696528503212, 5149.958809832038, 1454.6851291134763, 260.33482786891796, 4141.695806278145, 1462.2093263597699, 75.361076909601, 3615.537281815285, 620.4401244562852, 3682.5261692832983, 751.9360440406462, 6274.434508204856, 1524.5104584600167, 4799.613268050696, 1371.0748388815225, 3362.2405966665006, 782.7881318405589, 494.5913523285701, 1719.8298598045687, 1133.8688310569926, 1404.8392493321912, 2768.4233045836045, 1913.1129073314712, 928.6784736985466, 1567.0222210201562, 1608.1522101377473, 1385.7729590142355, 1349.6294360044747, 1401.2575940878503, 2226.2216631294846, 2532.0732865925097, 1715.4551662173885, 1395.7721018602015, 1729.6189693253443, 50.99111657187121, 26.676338699783255, 19.54644581206211, 16.375465916887144, 13.460049008534051, 16.301532220715664, 12.684003621865063, 12.080000101638635, 11.464066517364296, 9.815633130947825, 10.182084446254931, 9.483810697967542, 16.88019614649943, 8.462273711240874, 13.633385435816388, 11.983747398871243, 8.998610789038082, 9.647682279670953, 37.87517287273341, 7.425080883570261, 11.655655287673978, 9.991338671827132, 9.489985188489918, 7.578195582962608, 15.109411614452146, 8.35714697354674, 9.06288554244099, 19.9818495144773, 21.95761252869457, 8.683430081738184, 27.879095857248842, 32.167025031199096, 17.607248052354247, 16.431577135905712, 13.203712157764711, 46.84827664087636, 75.67813605015903, 40.105913241286785, 15.30818237499106, 40.67854064267744, 14.146903741809822, 66.46177885090792, 30.010604292557627, 90.46100519061243, 1045.1403347761168, 16.66532279974234, 459.6155921657303, 144.08445467298628, 53.245678747406274, 21.25020349068141, 55.35394327097367, 27.543662573254828, 84.8395027971294, 250.16777040373603, 56.28885534805737, 253.3032012160802, 55.79594520470355, 938.4019275727039, 593.0521568754023, 82.00272846080213, 605.5464585211386, 228.69784777706056, 1608.1522101377473, 2768.4233045836045, 1429.9127364795486, 1145.0143018967829, 3615.537281815285, 3734.696528503212, 751.9360440406462, 637.832865034293, 1913.1129073314712, 1401.2575940878503, 1371.0748388815225, 994.1341443718768, 3682.5261692832983, 1116.8434107552632, 1347.954625539483, 1457.0871373177804, 1395.7721018602015, 4151.123018756766, 5149.958809832038, 1462.2093263597699, 6274.434508204856, 1095.0139647660694, 4799.613268050696], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -8.4822998046875, -8.550700187683105, -8.476900100708008, -8.622699737548828, -8.64780044555664, -8.687100410461426, -8.810799598693848, -8.887900352478027, -8.986100196838379, -8.843099594116211, -9.094300270080566, -9.098600387573242, -9.117400169372559, -8.431900024414062, -9.181900024414062, -8.868399620056152, -9.233099937438965, -9.269000053405762, -9.353799819946289, -8.944700241088867, -8.973199844360352, -9.409199714660645, -8.578200340270996, -9.407699584960938, -7.036099910736084, -9.193900108337402, -9.284600257873535, -9.324700355529785, -9.29580020904541, -9.28279972076416, -8.380499839782715, -8.486200332641602, -8.513400077819824, -8.856300354003906, -7.440400123596191, -6.206999778747559, -8.95199966430664, -6.05049991607666, -8.670299530029297, -5.047999858856201, -5.359799861907959, -5.9980998039245605, -5.95389986038208, -7.897200107574463, -4.401000022888184, -4.093299865722656, -7.434899806976318, -6.226600170135498, -6.799600124359131, -4.431700229644775, -5.72629976272583, -4.343599796295166, -6.033699989318848, -5.198500156402588, -5.167799949645996, -4.535200119018555, -4.294600009918213, -5.627699851989746, -6.374000072479248, -5.927599906921387, -6.1666998863220215, -5.360300064086914, -5.42140007019043, -5.6859002113342285, -4.213399887084961, -6.599599838256836, -5.304800033569336, -5.475900173187256, -5.541399955749512, -4.667900085449219, -4.978000164031982, -4.798999786376953, -5.400000095367432, -5.261899948120117, -5.216100215911865, -5.4380998611450195, -5.510499954223633, -5.696000099182129, -5.630099773406982, -5.631100177764893, -5.581999778747559, -5.663300037384033, -7.7683000564575195, -8.156800270080566, -8.434800148010254, -8.257699966430664, -7.404900074005127, -8.937800407409668, -8.945099830627441, -8.89169979095459, -8.638400077819824, -8.904399871826172, -8.920299530029297, -8.950200080871582, -8.677200317382812, -8.495200157165527, -9.262299537658691, -9.294400215148926, -9.317700386047363, -9.182999610900879, -8.797200202941895, -9.410200119018555, -9.453700065612793, -9.402099609375, -9.483599662780762, -9.493200302124023, -8.812299728393555, -9.215399742126465, -9.196900367736816, -9.277000427246094, -9.378999710083008, -9.212400436401367, -7.871399879455566, -8.536399841308594, -5.978400230407715, -6.745299816131592, -7.657400131225586, -8.203300476074219, -6.5370001792907715, -7.7316999435424805, -7.804699897766113, -7.1616997718811035, -5.4670000076293945, -6.759399890899658, -7.164599895477295, -6.967899799346924, -5.734300136566162, -5.412700176239014, -6.921800136566162, -5.774099826812744, -6.289899826049805, -5.789599895477295, -5.892499923706055, -6.517899990081787, -6.678400039672852, -5.745699882507324, -5.332900047302246, -6.717800140380859, -5.371600151062012, -4.933499813079834, -6.184899806976318, -6.658899784088135, -5.528900146484375, -5.36870002746582, -6.673799991607666, -5.3769001960754395, -5.4421000480651855, -6.323500156402588, -5.2220001220703125, -5.946499824523926, -3.8673999309539795, -5.2133002281188965, -5.995699882507324, -5.575500011444092, -6.040999889373779, -6.006400108337402, -5.247600078582764, -5.122799873352051, -4.845099925994873, -4.392000198364258, -4.349100112915039, -5.759399890899658, -5.015500068664551, -4.723700046539307, -5.402900218963623, -4.821800231933594, -4.950500011444092, -5.013999938964844, -5.472499847412109, -5.144800186157227, -5.4980998039245605, -5.461900234222412, -5.366499900817871, -5.568900108337402, -5.399799823760986, -7.158299922943115, -8.060799598693848, -8.375100135803223, -8.392200469970703, -8.727399826049805, -5.504300117492676, -8.168000221252441, -8.48859977722168, -8.65410041809082, -8.91759967803955, -8.834199905395508, -8.179400444030762, -8.889800071716309, -8.802300453186035, -8.573100090026855, -8.946700096130371, -8.987500190734863, -8.605600357055664, -9.022700309753418, -9.05519962310791, -8.901200294494629, -8.907500267028809, -8.997599601745605, -9.135600090026855, -9.101200103759766, -8.433699607849121, -7.073400020599365, -8.978899955749512, -8.814000129699707, -8.788299560546875, -5.039400100708008, -8.030500411987305, -8.271400451660156, -7.97599983215332, -8.657500267028809, -7.62470006942749, -5.660200119018555, -6.663300037384033, -6.40310001373291, -7.776700019836426, -7.231800079345703, -6.246799945831299, -5.073699951171875, -7.547500133514404, -7.381199836730957, -5.940999984741211, -6.403800010681152, -7.066199779510498, -6.828999996185303, -6.566400051116943, -7.111499786376953, -5.868199825286865, -7.371600151062012, -7.162799835205078, -6.706200122833252, -5.827600002288818, -6.207900047302246, -6.595699787139893, -5.223100185394287, -6.041600227355957, -4.894000053405762, -5.9953999519348145, -6.3917999267578125, -6.058499813079834, -6.4593000411987305, -5.012599945068359, -5.653299808502197, -5.027400016784668, -5.705100059509277, -5.703700065612793, -5.105100154876709, -4.416299819946289, -5.396900177001953, -5.142300128936768, -5.617199897766113, -5.272299766540527, -5.399899959564209, -5.083099842071533, -5.241099834442139, -5.455100059509277, -5.253799915313721, -5.013000011444092, -5.366199970245361, -4.916100025177002, -5.395999908447266, -5.01230001449585, -5.440400123596191, -5.080599784851074, -5.161099910736084, -5.069200038909912, -5.492199897766113, -5.316100120544434, -5.498000144958496, -5.563199996948242, -7.8069000244140625, -7.940800189971924, -7.748199939727783, -7.997600078582764, -8.036299705505371, -8.316100120544434, -8.30090045928955, -8.175000190734863, -8.409299850463867, -8.483699798583984, -8.056099891662598, -8.585200309753418, -8.143899917602539, -8.369000434875488, -8.637299537658691, -7.9475998878479, -8.641300201416016, -8.649299621582031, -8.71030044555664, -8.398099899291992, -8.50469970703125, -8.765800476074219, -8.784899711608887, -8.200400352478027, -8.054400444030762, -8.84850025177002, -8.844900131225586, -8.746299743652344, -8.882499694824219, -8.868900299072266, -7.524600028991699, -7.893499851226807, -8.158100128173828, -8.1806001663208, -8.384699821472168, -8.11299991607666, -6.582600116729736, -8.187100410461426, -7.92110013961792, -7.4721999168396, -5.982800006866455, -7.4328999519348145, -6.898099899291992, -7.396900177001953, -5.626699924468994, -7.751800060272217, -7.087200164794922, -7.358699798583984, -5.496399879455566, -6.510000228881836, -7.005300045013428, -4.46120023727417, -5.531400203704834, -7.244900226593018, -6.4944000244140625, -4.684999942779541, -4.508999824523926, -5.321000099182129, -6.390999794006348, -4.7118000984191895, -5.350599765777588, -7.178800106048584, -4.9934000968933105, -5.986599922180176, -5.002799987792969, -5.89300012588501, -4.758299827575684, -5.5278000831604, -4.94920015335083, -5.623700141906738, -5.180799961090088, -5.914599895477295, -6.156199932098389, -5.552999973297119, -5.764100074768066, -5.674699783325195, -5.35830020904541, -5.533599853515625, -5.881499767303467, -5.671199798583984, -5.675099849700928, -5.736800193786621, -5.7846999168396, -5.7779998779296875, -5.673999786376953, -5.673999786376953, -5.75629997253418, -5.843800067901611, -5.830599784851074, -6.558899879455566, -7.215099811553955, -7.541399955749512, -7.723599910736084, -7.931399822235107, -7.740699768066406, -7.993100166320801, -8.045000076293945, -8.100299835205078, -8.270000457763672, -8.235099792480469, -8.306599617004395, -7.730199813842773, -8.432000160217285, -7.955900192260742, -8.087599754333496, -8.376899719238281, -8.31089973449707, -6.94350004196167, -8.573599815368652, -8.125499725341797, -8.279999732971191, -8.333499908447266, -8.559499740600586, -7.872300148010254, -8.46619987487793, -8.387200355529785, -7.597799777984619, -7.504300117492676, -8.433099746704102, -7.273900032043457, -7.151400089263916, -7.742599964141846, -7.812600135803223, -8.024499893188477, -6.843100070953369, -6.398600101470947, -6.99429988861084, -7.886099815368652, -6.995999813079834, -7.96150016784668, -6.5665998458862305, -7.285600185394287, -6.303999900817871, -4.269800186157227, -7.817800045013428, -5.124100208282471, -6.111299991607666, -6.900400161743164, -7.631499767303467, -6.915999889373779, -7.4456000328063965, -6.654600143432617, -5.91480016708374, -6.9695000648498535, -5.998899936676025, -7.019100189208984, -5.3379998207092285, -5.693699836730957, -6.835899829864502, -5.722899913787842, -6.3592000007629395, -5.470300197601318, -5.262899875640869, -5.580599784851074, -5.746600151062012, -5.272600173950195, -5.273099899291992, -5.935299873352051, -6.025100231170654, -5.639200210571289, -5.756999969482422, -5.782100200653076, -5.896699905395508, -5.4552001953125, -5.874300003051758, -5.819300174713135, -5.796899795532227, -5.845900058746338, -5.548299789428711, -5.53000020980835, -5.872900009155273, -5.665900230407715, -5.995999813079834, -5.919000148773193], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 1.1083, 1.1066, 1.105, 1.1035, 1.0998, 1.098, 1.0961, 1.0951, 1.0919, 1.0886, 1.0882, 1.0877, 1.0866, 1.086, 1.0848, 1.0801, 1.0795, 1.0784, 1.075, 1.0746, 1.0735, 1.0729, 1.072, 1.071, 1.0705, 1.0703, 1.0695, 1.0691, 1.068, 1.0677, 1.0575, 1.0579, 1.0539, 1.0605, 1.0066, 0.9459, 1.0569, 0.9034, 1.042, 0.8069, 0.7313, 0.7855, 0.7688, 0.9568, 0.5471, 0.4988, 0.8979, 0.7246, 0.7981, 0.4438, 0.627, 0.396, 0.6217, 0.4606, 0.4532, 0.3079, 0.2271, 0.4876, 0.638, 0.5363, 0.5819, 0.3991, 0.402, 0.4563, 0.1108, 0.6612, 0.308, 0.3533, 0.3633, 0.0695, 0.1644, 0.0581, 0.2384, 0.0985, 0.0155, 0.1804, 0.2011, 0.3293, 0.215, 0.1932, -0.07, 0.164, 1.2307, 1.2283, 1.2265, 1.223, 1.2128, 1.2118, 1.2104, 1.2095, 1.208, 1.2071, 1.2035, 1.2032, 1.2001, 1.1983, 1.197, 1.1936, 1.1898, 1.1885, 1.1876, 1.1859, 1.1852, 1.1843, 1.1837, 1.1824, 1.1807, 1.1792, 1.1741, 1.1736, 1.1735, 1.1711, 1.161, 1.1652, 1.1295, 1.1436, 1.1558, 1.1602, 1.1096, 1.1397, 1.1395, 1.1182, 1.0658, 1.0967, 1.1104, 1.1001, 1.0413, 1.0144, 1.0826, 1.0031, 1.0312, 0.9885, 0.9946, 1.0365, 1.0452, 0.9714, 0.9264, 1.0439, 0.9197, 0.8718, 0.9927, 1.0324, 0.8932, 0.8589, 1.0262, 0.8439, 0.8526, 0.9765, 0.7507, 0.8881, 0.4568, 0.7289, 0.8633, 0.7318, 0.8573, 0.845, 0.5648, 0.5156, 0.3865, 0.2002, 0.1727, 0.7276, 0.3449, 0.1334, 0.5018, -0.0821, -0.1075, -0.0659, 0.3518, -0.4075, 0.2612, 0.1509, -0.2241, 0.292, -0.5243, 1.5259, 1.5194, 1.517, 1.5137, 1.5107, 1.5094, 1.5094, 1.5075, 1.505, 1.5038, 1.5032, 1.5022, 1.4993, 1.4985, 1.4981, 1.498, 1.4972, 1.4961, 1.4956, 1.495, 1.4941, 1.4936, 1.4927, 1.491, 1.4907, 1.489, 1.4882, 1.4877, 1.4875, 1.4871, 1.4586, 1.4823, 1.484, 1.4798, 1.4863, 1.4733, 1.4165, 1.4144, 1.4006, 1.454, 1.4308, 1.3865, 1.2866, 1.4278, 1.4079, 1.3116, 1.3351, 1.3758, 1.3515, 1.3195, 1.3708, 1.2442, 1.381, 1.3368, 1.2739, 1.1248, 1.1791, 1.2329, 0.9804, 1.1191, 0.8902, 1.1095, 1.1772, 1.0933, 1.1693, 0.7682, 0.9426, 0.7116, 0.9075, 0.9067, 0.6809, 0.321, 0.6731, 0.5434, 0.7673, 0.5898, 0.6397, 0.4289, 0.4703, 0.5637, 0.3647, 0.1295, 0.4369, -0.059, 0.4385, -0.1369, 0.3869, -0.5589, -0.4215, -0.745, 0.2194, -0.4731, -0.2663, 0.2602, 2.191, 2.1885, 2.1856, 2.1715, 2.1711, 2.169, 2.1649, 2.163, 2.1616, 2.1583, 2.1577, 2.1496, 2.1485, 2.1475, 2.1471, 2.1463, 2.1448, 2.1419, 2.1416, 2.1405, 2.1362, 2.1354, 2.134, 2.1336, 2.1293, 2.127, 2.1264, 2.1262, 2.1254, 2.1245, 2.1184, 2.119, 2.1188, 2.1162, 2.1195, 2.1122, 2.0368, 2.1085, 2.0895, 2.0187, 1.8209, 1.9783, 1.8837, 1.9557, 1.6074, 1.9892, 1.8099, 1.8811, 1.2168, 1.5438, 1.6207, 0.2761, 0.7639, 1.6462, 1.2235, 0.158, 0.0127, 0.4649, 1.1155, 0.0278, 0.4302, 1.5674, -0.118, 0.6514, -0.1457, 0.5528, -0.434, 0.2112, -0.357, 0.2214, -0.2327, 0.491, 0.7085, 0.0654, 0.271, 0.1461, -0.2159, -0.0216, 0.3532, 0.0403, 0.0105, 0.0977, 0.0762, 0.0453, -0.3136, -0.4423, -0.1352, -0.0165, -0.2177, 2.5779, 2.5696, 2.5543, 2.5491, 2.5374, 2.5365, 2.5351, 2.5319, 2.529, 2.5145, 2.5127, 2.5123, 2.5121, 2.5009, 2.5, 2.4973, 2.4945, 2.4909, 2.4906, 2.49, 2.4872, 2.4867, 2.4847, 2.4837, 2.4809, 2.4791, 2.4771, 2.4758, 2.4751, 2.4739, 2.4666, 2.4461, 2.4576, 2.4567, 2.4635, 2.3785, 2.3434, 2.3826, 2.454, 2.3668, 2.4574, 2.3052, 2.3813, 2.2595, 1.8468, 2.4373, 1.814, 1.9867, 2.1931, 2.3806, 2.1387, 2.3071, 1.9731, 1.6316, 2.0685, 1.5349, 2.0277, 0.8863, 0.9895, 1.8258, 0.9394, 1.2769, 0.2153, -0.1205, 0.2225, 0.2787, -0.3971, -0.43, 0.5105, 0.5853, -0.1272, 0.0664, 0.063, 0.2699, -0.5981, 0.1759, 0.0428, -0.0126, -0.0186, -0.8109, -1.0083, -0.0922, -1.3416, 0.074, -1.3269]}, \"token.table\": {\"Topic\": [5, 2, 3, 4, 1, 4, 1, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 2, 1, 2, 3, 4, 5, 1, 3, 3, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 3, 4, 1, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 5, 4, 5, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 4, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 5, 1, 1, 2, 3, 4, 5, 4, 1, 3, 5, 1, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 4, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 2, 4, 5, 5, 3, 1, 3, 1, 2, 3, 4, 5, 1, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 1, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 5, 1, 2, 3, 4, 5, 3, 5, 4, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 5, 2, 5, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 5, 1, 3, 1, 2, 3, 4, 5, 2, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 3, 1, 4, 4, 2, 1, 2, 3, 4, 5, 1, 2, 4, 1, 4, 1, 2, 3, 4, 5, 1, 2, 3, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 2, 3, 4, 5, 2, 1, 5, 3, 2, 2, 1, 2, 3, 4, 5, 1, 3, 1, 1, 2, 3, 4, 5, 1, 3, 3, 5, 3, 1, 1, 2, 3, 4, 2, 3, 5, 1, 2, 3, 4, 5, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 4, 3, 5, 1, 2, 3, 4, 5, 2, 4, 2, 5, 1, 1, 2, 3, 4, 5, 1, 3, 4, 4, 1, 2, 3, 4, 5, 1, 2, 2, 1, 2, 3, 4, 5, 4, 3, 4, 1, 2, 3, 4, 5, 4, 1, 2, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 1, 1, 2, 3, 4, 5, 1, 4, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 5, 4, 5, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 3, 4, 5, 4, 3, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 3, 1, 4, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 3, 4, 4, 1, 2, 3, 4, 1, 2, 3, 4, 5, 1, 5, 1, 2, 3, 4, 5, 3, 4, 1, 2, 3, 4, 5, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 4, 1, 1, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 5, 2, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 4, 1, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 1, 2, 3, 4, 5, 1, 2, 3, 5, 2, 1, 2, 3, 4, 5, 2, 4, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 2, 1, 2, 3, 4, 5, 3, 4, 1, 5, 2, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 5, 4, 1, 2, 3, 4, 5, 3, 5, 5, 3, 5, 3, 3, 5, 5, 2, 1, 2, 3, 4, 5, 3, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, 1, 2, 1, 3, 4, 5, 1, 2], \"Freq\": [0.9328665413209438, 0.928227386356051, 0.9428383850376685, 0.9183991329177298, 0.05757669686149368, 0.9212271497838989, 0.9280115899162373, 0.3304610792428814, 0.38306811203715174, 0.1452250482771407, 0.11558728332262219, 0.025933044335203697, 0.9007801952883012, 0.1822802802147746, 0.01736002668712139, 0.6770410407977342, 0.07812012009204626, 0.04340006671780348, 0.9212442624725715, 0.03498999828365632, 0.007497856775069213, 0.8672521003163389, 0.06498142538393317, 0.024992855916897375, 0.8724085950341637, 0.07300612545754638, 0.07300612545754638, 0.07300612545754638, 0.7543966297279794, 0.02433537515251546, 0.06403650710563003, 0.04269100473708668, 0.02134550236854334, 0.06403650710563003, 0.811129090004647, 0.8886932489424916, 0.9568686959104606, 0.4809965011741762, 0.05423699419768159, 0.2733259049698954, 0.11204221169784223, 0.07921455731503495, 0.0536838209803469, 0.9126249566658973, 0.06618391407402657, 0.8603908829623456, 0.9237027368015528, 0.4471559867434339, 0.11091564514925019, 0.21746453261545903, 0.12576262127159077, 0.09781537210012616, 0.046297121596628465, 0.01543237386554282, 0.18518848638651386, 0.6481597023527985, 0.09259424319325693, 0.8763487848705787, 0.06507148896844171, 0.032535744484220856, 0.878465101073963, 0.03422072881957437, 0.9581804069480824, 0.7153906755999075, 0.18095175912232958, 0.008416360889410678, 0.07153906755999076, 0.021040902223526694, 0.15716495855402868, 0.8059741464309164, 0.020149353660772907, 0.012089612196463746, 0.004029870732154581, 0.26373421120442664, 0.013880747958127717, 0.14574785356034103, 0.034701869895319294, 0.5413491703669809, 0.14267007067364165, 0.7733131366948113, 0.012406093102055796, 0.05789510114292705, 0.014473775285731762, 0.6001933582389389, 0.3443732383338174, 0.009839235380966212, 0.03771706896037048, 0.008199362817471844, 0.9105960188284986, 0.2350495057684739, 0.5939921007843699, 0.08799882974583259, 0.0463151735504382, 0.03589425950158961, 0.9365427819173638, 0.9427506729912057, 0.10009083486245629, 0.9008175137621067, 0.027501926687488017, 0.22001541349990414, 0.041252890031232024, 0.7012991305309444, 0.1792758453939088, 0.06996130551957416, 0.2711000588883499, 0.20988391655872252, 0.26672747729337654, 0.9546441015644058, 0.2872884173245484, 0.6663495235166609, 0.009975292268213486, 0.027930818350997758, 0.005985175360928092, 0.6634999478912845, 0.11682889447919627, 0.03526910022013472, 0.13666776335302205, 0.04629069403892683, 0.9276913403429079, 0.05301093373388045, 0.0706868455635699, 0.0706868455635699, 0.8482421467628387, 0.05387929938199622, 0.8620687901119395, 0.02693964969099811, 0.033674562113747634, 0.02693964969099811, 0.046166734651852066, 0.9233346930370413, 0.9650099237937028, 0.9629665143458912, 0.3339952359844194, 0.59176749280227, 0.004157617045449204, 0.05959251098477192, 0.009701106439381475, 0.9687929713941139, 0.15383255384861227, 0.7971323244882637, 0.009323185081734077, 0.027969555245202234, 0.013984777622601117, 0.9212949174110953, 0.9879540173950593, 0.09401101053812506, 0.03418582201386366, 0.7618554620232473, 0.08546455503465915, 0.024418444295616896, 0.8718875706458216, 0.062175473114476125, 0.062175473114476125, 0.8704566236026658, 0.9712103763694612, 0.9595199036344226, 0.05043857812834713, 0.007005358073381545, 0.9050922630808956, 0.02662036067884987, 0.011208572917410472, 0.19929339886677572, 0.061686052030192486, 0.28470485552396535, 0.3653712312557555, 0.0854114566571896, 0.24144256033548883, 0.054873309167156555, 0.5220803415046609, 0.04860207383376723, 0.13326375083452305, 0.09032780149958863, 0.198721163299095, 0.018065560299917727, 0.07226224119967091, 0.6322946104971204, 0.9718033940368057, 0.9350345160786537, 0.030162403744472703, 0.030162403744472703, 0.030162403744472703, 0.3250206452462447, 0.18009340671021426, 0.22378470656298816, 0.09057952408501901, 0.18009340671021426, 0.19598386762538808, 0.7167084461416808, 0.014812734180988635, 0.06836646545071677, 0.0034183232725358385, 0.2102492966062614, 0.6833102139703495, 0.021024929660626142, 0.07288642282350395, 0.011914126807688146, 0.07020776817432883, 0.8010068096252971, 0.02872135970767998, 0.08297281693329772, 0.01914757313845332, 0.9746464945060564, 0.047967023006262106, 0.017442553820458947, 0.8416032218371442, 0.07413085373695052, 0.017442553820458947, 0.967174909001824, 0.4048636452295344, 0.13553375248027333, 0.04344030528213889, 0.3614233399473955, 0.05212836633856666, 0.9368485797100154, 0.1590341775043703, 0.05831253175160244, 0.7209549380198119, 0.021204557000582706, 0.04240911400116541, 0.43805433386997966, 0.2567812384971335, 0.13120209266276897, 0.12557914583436458, 0.04846444647339017, 0.0925493419191747, 0.0077124451599312254, 0.6375621332209813, 0.17224460857179738, 0.08740771181255388, 0.10322088044344246, 0.10322088044344246, 0.7741566033258185, 0.9743349491322605, 0.03159595968643669, 0.8467717195965033, 0.03159595968643669, 0.07583030324744805, 0.012638383874574676, 0.9061164356255824, 0.2255806405260406, 0.1725028427552075, 0.06634724721354135, 0.5175085282656225, 0.01326944944270827, 0.08024354799906586, 0.7553360061651199, 0.017444249565014315, 0.13955399652011452, 0.006977699826005726, 0.12409225547714918, 0.8113724396582831, 0.00954555811362686, 0.03818223245450744, 0.01431833717044029, 0.8633020088440715, 0.06085843079632537, 0.06085843079632537, 0.8520180311485551, 0.8890261160917673, 0.9721352183071081, 0.046312952785891454, 0.9725720085037205, 0.3817302915303901, 0.026483680512873954, 0.4127801238558285, 0.09954210951390556, 0.08036427190113477, 0.9787643758997762, 0.9664073586414187, 0.25385198104244416, 0.13250155082835585, 0.42899016951358776, 0.13250155082835585, 0.051819913442772834, 0.07323199047949343, 0.012205331746582237, 0.8787838857539211, 0.036615995239746714, 0.05587054338980345, 0.8939286942368552, 0.965821149072907, 0.39074021166706135, 0.4064555401070528, 0.12072229574357106, 0.05286065020724413, 0.029287657547256884, 0.8886152666603143, 0.31184637425806533, 0.5923473655365828, 0.013663372068008016, 0.07474668248969091, 0.006429822149650831, 0.9240828858992614, 0.056342600387005816, 0.03756173359133721, 0.22537040154802326, 0.6573303378484012, 0.041551701791361854, 0.013850567263787285, 0.8587351703548116, 0.02770113452757457, 0.05540226905514914, 0.1666077747471402, 0.799717318786273, 0.905147359646294, 0.1239077111853292, 0.8100235447637939, 0.01294558176563141, 0.0369873764732326, 0.016644319412954668, 0.056794792521043115, 0.056794792521043115, 0.8519218878156467, 0.2107912430292507, 0.7217668740373296, 0.013243428881418893, 0.0386266675708051, 0.016554286101773615, 0.9108744257555489, 0.11116788689939869, 0.1609008889333402, 0.1170188283151565, 0.5353611395418411, 0.07606223840485173, 0.1195212079099702, 0.19256194607717422, 0.01992020131832837, 0.5046451000643186, 0.1660016776527364, 0.010341759259763217, 0.020683518519526434, 0.8531951389304654, 0.07756319444822413, 0.03619615740917126, 0.7217963986765006, 0.19517963841762517, 0.013994011811075012, 0.03608981993382503, 0.033880239121550026, 0.05675995100422767, 0.9081592160676427, 0.014189987751056917, 0.014189987751056917, 0.972043725119331, 0.9153219040338181, 0.4799521645425733, 0.3715110897086864, 0.041502139751240646, 0.09371450911570468, 0.014057176367355703, 0.1598895544126677, 0.01776550604585197, 0.2131860725502236, 0.01776550604585197, 0.5862616995131149, 0.9323402986592538, 0.037683839120513526, 0.007536767824102706, 0.8139709250030922, 0.09044121388923247, 0.05275737476871894, 0.8827210674278566, 0.9803994515128581, 0.8376064250344549, 0.10760750690628908, 0.8608600552503126, 0.398957069656551, 0.12180224978545524, 0.2662144980340788, 0.13347192641160663, 0.07949967201565641, 0.24556641749839458, 0.19957694708350088, 0.36965121503291903, 0.11453981310879181, 0.0702857944076677, 0.9274322897150893, 0.9135673055087972, 0.02946991308092894, 0.02946991308092894, 0.25077014417514926, 0.2737414550919568, 0.3369125601131776, 0.08678050790793969, 0.051685449562817024, 0.2451571024212531, 0.01077613637016497, 0.6277099435621095, 0.061962784128448585, 0.053880681850824855, 0.14489117643809243, 0.7884168519694399, 0.011747933224710197, 0.0456864069849841, 0.00913728139699682, 0.10897848966587849, 0.8554811438771462, 0.005448924483293925, 0.016346773449881773, 0.005448924483293925, 0.30793136298921914, 0.0947481116889905, 0.20923541331318735, 0.04342621785745398, 0.34346190487259054, 0.2121653169401771, 0.08250873436562442, 0.08250873436562442, 0.09429569641785648, 0.5304132923504428, 0.9754935704206775, 0.5302510552133757, 0.34919480099709926, 0.025627064750980432, 0.07500604317360127, 0.019793261393033668, 0.9412537885839025, 0.042784263117450115, 0.2346823020372263, 0.66475620396065, 0.014866752165254155, 0.06796229561259041, 0.016990573903147604, 0.03449706404311929, 0.9314207291642207, 0.03449706404311929, 0.4586889306987411, 0.26918364477625656, 0.16007454076028055, 0.06962883611545835, 0.043069383164201044, 0.8824859923260474, 0.2275206460318331, 0.6711287398024424, 0.01143319829305694, 0.08231902771000997, 0.009146558634445552, 0.8854035360890202, 0.02951345120296734, 0.03935126827062312, 0.03935126827062312, 0.00983781706765578, 0.3796384744557985, 0.22865000412038103, 0.239486497206655, 0.08633072825398272, 0.06574139139006216, 0.35971369165597333, 0.45135541638002497, 0.09992932417735723, 0.0694883338777157, 0.019443983332755314, 0.947122690450021, 0.4785479409172462, 0.26341866979854467, 0.13810768022435158, 0.11034127598344172, 0.009899326729367858, 0.12439648116237922, 0.7712581832067512, 0.03040802872858159, 0.06634478995326892, 0.005528732496105744, 0.07176341114431013, 0.1076451167164652, 0.7893975225874115, 0.035881705572155066, 0.9741814865112564, 0.9244107475920583, 0.15761906407912699, 0.07726424709761127, 0.5408497296832789, 0.13907564477570028, 0.08653595674932463, 0.9186240656107761, 0.0353316948311837, 0.0353316948311837, 0.9136256126250677, 0.023466466600212402, 0.004693293320042481, 0.9527385439686236, 0.014079879960127443, 0.004693293320042481, 0.033096578347496464, 0.01103219278249882, 0.9377363865123998, 0.02206438556499764, 0.01103219278249882, 0.960577815941886, 0.9065859146488124, 0.06973737804990865, 0.957331331957493, 0.9355600903416194, 0.31025938927435287, 0.06913388565352427, 0.3439832359346086, 0.07756484731858822, 0.20065688762852169, 0.979375277446004, 0.06255722590057218, 0.8758011626080106, 0.051066319528888626, 0.9191937515199952, 0.28725847325962744, 0.15958804069979302, 0.2447016624063493, 0.18618604748309187, 0.12368073154233959, 0.06822245597983209, 0.9551143837176492, 0.948542139286528, 0.2610877482083546, 0.036987430996183575, 0.16753130510036088, 0.0783263244625064, 0.4569035593646206, 0.9460735236084324, 0.15337824593992283, 0.030675649187984568, 0.24540519350387655, 0.5521616853837222, 0.015337824593992284, 0.11458340292704386, 0.6774492418669085, 0.03618423250327701, 0.14674716515217898, 0.024122821668851338, 0.9550259369538037, 0.9437205479537616, 0.9428036138594861, 0.01886365385477971, 0.9243190388842059, 0.05659096156433913, 0.01886365385477971, 0.9609164984047007, 0.9381225592372241, 0.04690612796186121, 0.9264389545295922, 0.9776753995674143, 0.9192704198669992, 0.16377156539160345, 0.0606561353302235, 0.4994021808855068, 0.2183620871888046, 0.05863426415254938, 0.9599160995130861, 0.9600177698967463, 0.9479694254306401, 0.3028320310291311, 0.1336938124666595, 0.3625278728747093, 0.10819871334511048, 0.09203108951193306, 0.03367478282553885, 0.9428939191150879, 0.07920755926528641, 0.8976856716732461, 0.9772881845799049, 0.9900919428605075, 0.08283877620663634, 0.8698071501696816, 0.0248516328619909, 0.016567755241327267, 0.024582986119980447, 0.17208090283986313, 0.7866555558393743, 0.3413417698114119, 0.32667792289827247, 0.19850503876860945, 0.09259947772926926, 0.040732908092053925, 0.9351033813063122, 0.2661043392106541, 0.5025631021697233, 0.11434722268468424, 0.08893672875475442, 0.027528035090757318, 0.4479483607962206, 0.13352306908348882, 0.22612777828655367, 0.15290545007947914, 0.039841560936202315, 0.30003456555036834, 0.20594707112690785, 0.32355643915623344, 0.10506436877286417, 0.06533853779406976, 0.5246048656245937, 0.23411328247363472, 0.12709006762854455, 0.07357846020599948, 0.04108926998516854, 0.3553105304384026, 0.403823219802938, 0.14688564279817656, 0.07815933286508477, 0.01572170488665498, 0.8916759210048997, 0.9125865442736049, 0.18823349158769564, 0.7999923392477065, 0.8424770464310636, 0.014780299060194098, 0.11824239248155279, 0.014780299060194098, 0.014780299060194098, 0.9569586475847193, 0.03501068222870924, 0.9738547402324897, 0.01708517088127175, 0.9255322026367491, 0.08849443798591101, 0.8298166971793622, 0.027563841339873923, 0.04352185474716935, 0.010155099441006182, 0.05005644263921252, 0.8843304866260879, 0.05005644263921252, 0.9231009878097416, 0.4628987242911184, 0.4721876619023114, 0.016255640819587767, 0.027866812833579033, 0.020900109625184276, 0.06737356653919728, 0.9432299315487619, 0.9267646992278529, 0.5085047840304736, 0.0873685825843864, 0.2571974004169577, 0.06479018483785957, 0.08246023524818492, 0.9062890805032546, 0.06132806886395612, 0.9199210329593418, 0.1699487637465866, 0.039728282434267, 0.6488952797596943, 0.10152783288757122, 0.039728282434267, 0.8899845094360901, 0.04578714178968774, 0.9157428357937548, 0.8280288143232969, 0.013485811308197019, 0.08630919237246092, 0.053943245232788074, 0.01618297356983642, 0.9266299140856517, 0.32642048305142446, 0.11202157486537521, 0.3798347439143848, 0.10460292752329738, 0.0778957970918172, 0.3419713698063356, 0.15946851441746218, 0.39955722223486356, 0.07530457625269048, 0.023920277162619328, 0.4382468124153759, 0.33244316245229705, 0.12083586252613927, 0.08614614122676914, 0.022548318844590583, 0.9169046845917452, 0.12185169809217723, 0.7592298111897197, 0.009373207545552095, 0.09373207545552095, 0.015622012575920158, 0.9185619767744642, 0.05363551242036112, 0.01489875345010031, 0.7806946807852563, 0.05363551242036112, 0.09833177277066205, 0.9533212954327086, 0.9750428670734339, 0.5564741565059342, 0.2676786428943564, 0.06900160572387853, 0.08506232429753992, 0.02200913286020264, 0.06248418565857688, 0.8747785992200763, 0.11689652647520317, 0.011689652647520317, 0.023379305295040634, 0.8182756853264221, 0.03506895794256095, 0.9201589026667258, 0.07859021531519395, 0.011227173616456278, 0.7859021531519395, 0.03929510765759697, 0.08420380212342209, 0.3474758864323226, 0.08175903210172296, 0.2989314611219246, 0.17501542809275072, 0.0958113657442066, 0.945777169444362, 0.9379847714488426, 0.02099965906228752, 0.013999772708191681, 0.027999545416383363, 0.2790380068802938, 0.20420826568683154, 0.3258940130481627, 0.09790807258957678, 0.09301266896009792, 0.9553361466476276, 0.8429939395166738, 0.8457374309442207, 0.09397082566046897, 0.04706357977228426, 0.011765894943071065, 0.24708379380449239, 0.541231167381269, 0.15295663425992384, 0.06492839267410218, 0.9089974974374304, 0.08325062521604813, 0.8741315647685054, 0.016650125043209625, 0.008325062521604813, 0.016650125043209625, 0.17093401898913904, 0.007769728135869957, 0.7303544447717759, 0.06733764384420629, 0.02330918440760987, 0.09415323181929697, 0.8944557022833213, 0.9732960903102115, 0.9342469866003512, 0.06228313244002342, 0.91590928383434, 0.9472167517986332, 0.4040809017786824, 0.339808543062323, 0.12038931239922301, 0.10854455746962204, 0.02718468344498584, 0.8968578274261048, 0.1319114766332313, 0.0439704922110771, 0.4237156522158339, 0.023983904842405694, 0.3797451600047568, 0.046413952279449826, 0.8844436462139605, 0.018049870330897156, 0.046413952279449826, 0.005157105808827759, 0.30486790463259, 0.10975244566773242, 0.0853630132971252, 0.0365841485559108, 0.46339921504153686, 0.04511644562168573, 0.887290097226486, 0.04511644562168573, 0.015038815207228577, 0.9420949757856341, 0.058236527174798644, 0.8735479076219796, 0.5065710938491979, 0.2582405000865301, 0.11192364789303336, 0.09385264224363735, 0.029729718971586983, 0.017922449316544617, 0.3046816383812585, 0.1075346958992677, 0.5555959288128831, 0.15766048053834406, 0.027182841472128284, 0.6442333428894403, 0.06523881953310788, 0.10873136588851313, 0.07697488813228245, 0.9236986575873896, 0.9524111129132373, 0.048528031258747745, 0.889680573077042, 0.01617601041958258, 0.01617601041958258, 0.16361804509904634, 0.07499160400372958, 0.6851505638522566, 0.06476547618503918, 0.013634837091587195, 0.9473437290551983, 0.028707385728945402, 0.6090981310008082, 0.15461721786943594, 0.08902203453088735, 0.09605008988858899, 0.05153907262314531, 0.9467268188204039, 0.04303303721910927, 0.045043251797484134, 0.8952346294749972, 0.011260812949371033, 0.022521625898742067, 0.022521625898742067, 0.9570207571547242, 0.8579526206969369, 0.22586672511105382, 0.2879259530968386, 0.32617175639040363, 0.1183455045310314, 0.04113227901383408, 0.7899087362441498, 0.10532116483255331, 0.00877676373604611, 0.052660582416276656, 0.03510705494418444, 0.03640444562294908, 0.9465155861966762, 0.03640444562294908, 0.06299464469944266, 0.014537225699871382, 0.799547413492926, 0.11629780559897106, 0.004845741899957128, 0.40867201401626985, 0.47866228637319275, 0.05694123852766605, 0.03499513617846142, 0.02016668864521506, 0.8801922351930793, 0.23796818226824823, 0.1933491480929517, 0.2700023606505124, 0.22995963767268218, 0.06864466796199468, 0.16174484370816733, 0.804102937292032, 0.013863843746414344, 0.013863843746414344, 0.009242562497609562, 0.8787872450049338, 0.9486352174490994, 0.9522024424011571, 0.5761050728793017, 0.3114568050253725, 0.07741411916815617, 0.028805253643965086, 0.007201313410991271, 0.2822587457245089, 0.05453813052982035, 0.13299649374815842, 0.05836536775998319, 0.4707501793100283, 0.9484088810570516, 0.08344635168913779, 0.9179098685805157, 0.9774259767000405, 0.9637436725473639, 0.21949460795084963, 0.6987461483879118, 0.010390277299448504, 0.06364044845912209, 0.007792707974586377, 0.27395576799636007, 0.00817778411929433, 0.6828449739610766, 0.02453335235788299, 0.012266676178941494, 0.088384748300453, 0.8661705333444393, 0.013257712245067948, 0.02209618707511325, 0.008838474830045299, 0.27266149957981867, 0.674703553862218, 0.013900390174657423, 0.0288700411319808, 0.008554086261327644, 0.2900971430547159, 0.07355543674610095, 0.41589756291019697, 0.1704836290937667, 0.05018268114453616, 0.09869413330026618, 0.006168383331266636, 0.7525427664145296, 0.08018898330646626, 0.06168383331266636, 0.9688070961289986, 0.9360234529041518, 0.6946441785397925, 0.19646502019307263, 0.0385913432522107, 0.02455812752413408, 0.045607951116249004, 0.9059266788434907, 0.27883431967203337, 0.17568173898411352, 0.2739990424522871, 0.20630516137583974, 0.06447036292994991, 0.6025522378801568, 0.27157283960795797, 0.021822817468496625, 0.026672332461495873, 0.07637986113973819, 0.502000078696112, 0.16926944802315183, 0.18365181942381179, 0.09542150256207088, 0.050061715836912546, 0.027944093386144564, 0.13972046693072282, 0.8103787081981924, 0.9752973324086072, 0.1658173040239069, 0.011054486934927126, 0.088435895479417, 0.02210897386985425, 0.707487163835336, 0.9489856226177916, 0.5511644127968562, 0.23563294306302948, 0.09750328678470185, 0.07312746508852638, 0.043334794126534154, 0.9692378880821879, 0.09249699272931936, 0.013213856104188479, 0.052855424416753914, 0.0660692805209424, 0.7796175101471202, 0.927337776421702, 0.04415894173436676, 0.12000967662210069, 0.8400677363547048, 0.9681576205497406, 0.15203142133110462, 0.7675732735497233, 0.024102542406150732, 0.046351043088751404, 0.009270208617750282, 0.9088181907052026, 0.9168118214223648, 0.3937404280063899, 0.18187361747458852, 0.2622809009896698, 0.11167678265983506, 0.0504140904578684, 0.3420061587511633, 0.3208822489459444, 0.1659735770410057, 0.07343073408480859, 0.09757234529077306, 0.4458782578951781, 0.034679420058513856, 0.24936154423026627, 0.07926724584803167, 0.18991110984424253, 0.28227143890028866, 0.6732696542658737, 0.012545397284457274, 0.020908995474095457, 0.010454497737047729, 0.3226933502893579, 0.09255545705973832, 0.45402203936060825, 0.08505096054138116, 0.04627772852986916, 0.012473106833946269, 0.972902333047809, 0.012473106833946269, 0.16550866061945213, 0.015046241874495648, 0.030092483748991296, 0.030092483748991296, 0.7523120937247824, 0.10870220614975172, 0.13044264737970207, 0.021740441229950346, 0.6956941193584111, 0.021740441229950346, 0.057127750621096166, 0.9140440099375386, 0.7065561925246882, 0.20134055090413278, 0.07457057440893806, 0.016778379242011063, 0.0018642643602234516, 0.6688126606863126, 0.2238703466732427, 0.032647758889847896, 0.025185414000739804, 0.0494380348903411, 0.1216296148603716, 0.6944658654930895, 0.013732375871332279, 0.05885303944856691, 0.11182077495227713, 0.9567630471677064, 0.3797181497564307, 0.13182667840600612, 0.3102225638576122, 0.10531805285697228, 0.07307783259463382, 0.9468000453342854, 0.03381428733336734, 0.17453785325586085, 0.7978873291696497, 0.9756012265045875, 0.27674774084284337, 0.6056964028626303, 0.029829097815396294, 0.060486781681220264, 0.02734333966411327, 0.15189140959948474, 0.7798327248949156, 0.022228011160900205, 0.03704668526816701, 0.009261671317041753, 0.2653518843064296, 0.047872762632603275, 0.45410734840069394, 0.1648190827779627, 0.06770576429468178, 0.14378101072960978, 0.8131064055053794, 0.009915931774455846, 0.019831863548911692, 0.009915931774455846, 0.08295598746666441, 0.05184749216666526, 0.7984513793666449, 0.041477993733332205, 0.010369498433333051, 0.08789691083256361, 0.22749788686075287, 0.0051704065195625655, 0.6618120345040084, 0.015511219558687695, 0.4083364736010879, 0.19226209772146252, 0.21342856719538503, 0.14022786026473644, 0.04497874763208527, 0.3438115786055952, 0.30679666745136963, 0.1651434497650064, 0.12385758732375479, 0.05979331801836438, 0.883905456442201, 0.34520778919945716, 0.19030994659286193, 0.2902828932207578, 0.14140751727849363, 0.033003117320534285, 0.3572322641626219, 0.19206035707667843, 0.09603017853833921, 0.32650260703035333, 0.026888449990734982, 0.05440616962003552, 0.00680077120250444, 0.8636979427180639, 0.05440616962003552, 0.02040231360751332, 0.07573627689330759, 0.9088353227196911, 0.8596216244535654, 0.327004753134245, 0.4206039397197716, 0.16113277690672942, 0.06871839015139931, 0.022116263497002075, 0.09108458387205655, 0.8653035467845371, 0.9453723990720352, 0.21783595351716442, 0.7624258373100755, 0.9437689089647283, 0.06532454183676943, 0.8492190438780026, 0.9770714360865943, 0.9718303857521021, 0.07831859064352, 0.00978982383044, 0.8321350255874, 0.06852876681308, 0.01957964766088, 0.9211813105216414, 0.5104757315558095, 0.18226950794578725, 0.22647440522167583, 0.03269951305339705, 0.0484437230420697, 0.6249310839204207, 0.3274879237852205, 0.018026858190012138, 0.02103133455501416, 0.009013429095006069, 0.7957816796807266, 0.11936725195210898, 0.0044210093315595915, 0.07294665397073327, 0.008842018663119183, 0.38550324976642714, 0.15117774500644202, 0.3029369428782934, 0.11454621448565029, 0.0453533235019326, 0.04006109472143938, 0.8412829891502269, 0.08012218944287876, 0.04006109472143938, 0.04076967887796801, 0.06115451831695202, 0.8255859972788522, 0.06115451831695202, 0.010192419719492002, 0.41456124962665725, 0.22474054785376021, 0.1701223270606153, 0.10117801556762909, 0.08864268620526797, 0.24197295152284157, 0.07542014073439218, 0.5216559734128793, 0.1241289816253538, 0.036138817435229585, 0.02154028114932952, 0.02154028114932952, 0.9046918082718398, 0.02154028114932952, 0.04308056229865904, 0.2388326621567751, 0.08304239115221203, 0.5126666627330776, 0.09196430094542489, 0.0734341806056751, 0.24527108018603982, 0.053229042933991624, 0.5615142176174018, 0.09497731190182819, 0.04592309586462022, 0.9502803967369584, 0.03276828954265374, 0.026979987332771835, 0.9173195693142424, 0.05395997466554367, 0.9805629560891407, 0.07380296393290355, 0.910236555172477], \"Term\": [\"2006\", \"4.50\", \"a.m.\", \"accent\", \"alex\", \"alex\", \"alley\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"amazing\", \"angle\", \"answer\", \"answer\", \"answer\", \"answer\", \"answer\", \"appliance\", \"appointment\", \"appointment\", \"appointment\", \"appointment\", \"appointment\", \"arrogant\", \"artist\", \"artist\", \"artist\", \"artist\", \"artist\", \"asada\", \"asada\", \"asada\", \"asada\", \"asada\", \"asado\", \"asia\", \"ask\", \"ask\", \"ask\", \"ask\", \"ask\", \"availability\", \"availability\", \"avec\", \"avec\", \"awake\", \"bad\", \"bad\", \"bad\", \"bad\", \"bad\", \"bagel\", \"bagel\", \"bagel\", \"bagel\", \"bagel\", \"baker\", \"balloon\", \"balloon\", \"balloon\", \"balsamic\", \"balsamic\", \"bartender\", \"bartender\", \"bartender\", \"bartender\", \"bartender\", \"bbq\", \"bbq\", \"bbq\", \"bbq\", \"bbq\", \"bed\", \"bed\", \"bed\", \"bed\", \"bed\", \"beef\", \"beef\", \"beef\", \"beef\", \"beef\", \"beer\", \"beer\", \"beer\", \"beer\", \"beer\", \"biryani\", \"bit\", \"bit\", \"bit\", \"bit\", \"bit\", \"bitterness\", \"bi\\u00e8re\", \"blind\", \"blind\", \"bomb\", \"bomb\", \"bomb\", \"bomb\", \"book\", \"book\", \"book\", \"book\", \"book\", \"bowling\", \"bread\", \"bread\", \"bread\", \"bread\", \"bread\", \"breakfast\", \"breakfast\", \"breakfast\", \"breakfast\", \"breakfast\", \"brewery\", \"brewery\", \"bride\", \"bride\", \"bride\", \"broth\", \"broth\", \"broth\", \"broth\", \"broth\", \"brussel\", \"brussel\", \"bum\", \"bumper\", \"burger\", \"burger\", \"burger\", \"burger\", \"burger\", \"bust\", \"butter\", \"butter\", \"butter\", \"butter\", \"butter\", \"c'est\", \"cajun\", \"call\", \"call\", \"call\", \"call\", \"call\", \"calzone\", \"canal\", \"canal\", \"canal\", \"cannoli\", \"capacity\", \"car\", \"car\", \"car\", \"car\", \"car\", \"card\", \"card\", \"card\", \"card\", \"card\", \"care\", \"care\", \"care\", \"care\", \"care\", \"carne\", \"carne\", \"carne\", \"carne\", \"carne\", \"cesar\", \"chai\", \"chai\", \"chai\", \"chai\", \"check\", \"check\", \"check\", \"check\", \"check\", \"cheese\", \"cheese\", \"cheese\", \"cheese\", \"cheese\", \"chicken\", \"chicken\", \"chicken\", \"chicken\", \"chicken\", \"chocolate\", \"chocolate\", \"chocolate\", \"chocolate\", \"chocolate\", \"cirque\", \"class\", \"class\", \"class\", \"class\", \"class\", \"coca\", \"coffee\", \"coffee\", \"coffee\", \"coffee\", \"coffee\", \"cola\", \"color\", \"color\", \"color\", \"color\", \"color\", \"come\", \"come\", \"come\", \"come\", \"come\", \"company\", \"company\", \"company\", \"company\", \"company\", \"contract\", \"contract\", \"contract\", \"contractor\", \"cookie\", \"cookie\", \"cookie\", \"cookie\", \"cookie\", \"copa\", \"coupon\", \"coupon\", \"coupon\", \"coupon\", \"coupon\", \"cream\", \"cream\", \"cream\", \"cream\", \"cream\", \"crispy\", \"crispy\", \"crispy\", \"crispy\", \"crispy\", \"croque\", \"crown\", \"crown\", \"crown\", \"cr\\u00eape\", \"curl\", \"curly\", \"curly\", \"customer\", \"customer\", \"customer\", \"customer\", \"customer\", \"dang\", \"dash\", \"day\", \"day\", \"day\", \"day\", \"day\", \"dealership\", \"dealership\", \"dealership\", \"dealership\", \"death\", \"death\", \"dedicated\", \"definitely\", \"definitely\", \"definitely\", \"definitely\", \"definitely\", \"del\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"delicious\", \"denny\", \"dental\", \"dental\", \"dental\", \"dental\", \"dentist\", \"dentist\", \"dentist\", \"dentist\", \"dentist\", \"des\", \"des\", \"desperate\", \"dessert\", \"dessert\", \"dessert\", \"dessert\", \"dessert\", \"disgust\", \"disgust\", \"disgust\", \"dish\", \"dish\", \"dish\", \"dish\", \"dish\", \"disposal\", \"dog\", \"dog\", \"dog\", \"dog\", \"dog\", \"donut\", \"donut\", \"donut\", \"donut\", \"donut\", \"dr.\", \"dr.\", \"dr.\", \"dr.\", \"dr.\", \"drink\", \"drink\", \"drink\", \"drink\", \"drink\", \"dumpling\", \"dumpling\", \"dumpling\", \"dumpling\", \"dunkin\", \"earl\", \"eat\", \"eat\", \"eat\", \"eat\", \"eat\", \"elevator\", \"elevator\", \"elevator\", \"elevator\", \"elevator\", \"eliminate\", \"email\", \"email\", \"email\", \"email\", \"email\", \"embassy\", \"enchilada\", \"errand\", \"est\", \"est\", \"experience\", \"experience\", \"experience\", \"experience\", \"experience\", \"feel\", \"feel\", \"feel\", \"feel\", \"feel\", \"festival\", \"fianc\\u00e9\", \"fianc\\u00e9\", \"fianc\\u00e9\", \"find\", \"find\", \"find\", \"find\", \"find\", \"fix\", \"fix\", \"fix\", \"fix\", \"fix\", \"flavor\", \"flavor\", \"flavor\", \"flavor\", \"flavor\", \"flavorful\", \"flavorful\", \"flavorful\", \"flavorful\", \"flavorful\", \"floor\", \"floor\", \"floor\", \"floor\", \"floor\", \"fly\", \"fly\", \"fly\", \"fly\", \"fly\", \"fog\", \"food\", \"food\", \"food\", \"food\", \"food\", \"freezer\", \"freezer\", \"fresh\", \"fresh\", \"fresh\", \"fresh\", \"fresh\", \"freshness\", \"freshness\", \"freshness\", \"friendly\", \"friendly\", \"friendly\", \"friendly\", \"friendly\", \"froyo\", \"fry\", \"fry\", \"fry\", \"fry\", \"fry\", \"gel\", \"gel\", \"gel\", \"gel\", \"gel\", \"get\", \"get\", \"get\", \"get\", \"get\", \"good\", \"good\", \"good\", \"good\", \"good\", \"gooey\", \"great\", \"great\", \"great\", \"great\", \"great\", \"green\", \"green\", \"green\", \"green\", \"green\", \"groom\", \"groom\", \"groom\", \"groom\", \"grub\", \"gumbo\", \"guy\", \"guy\", \"guy\", \"guy\", \"guy\", \"gyro\", \"gyro\", \"gyro\", \"hahaha\", \"hair\", \"hair\", \"hair\", \"hair\", \"hair\", \"haircut\", \"haircut\", \"haircut\", \"haircut\", \"haircut\", \"hakka\", \"hall\", \"hall\", \"harness\", \"heartbeat\", \"help\", \"help\", \"help\", \"help\", \"help\", \"hibachi\", \"hills\", \"hills\", \"hollandaise\", \"hollandaise\", \"home\", \"home\", \"home\", \"home\", \"home\", \"horchata\", \"horchata\", \"horribly\", \"hotel\", \"hotel\", \"hotel\", \"hotel\", \"hotel\", \"humor\", \"hurt\", \"hurt\", \"hurt\", \"hurt\", \"hurt\", \"ice\", \"ice\", \"ice\", \"ice\", \"ice\", \"ikea\", \"ink\", \"instruct\", \"instructor\", \"instructor\", \"instructor\", \"instructor\", \"ipad\", \"izakaya\", \"izakaya\", \"j'ai\", \"jalape\\u00f1os\", \"jamba\", \"job\", \"job\", \"job\", \"job\", \"job\", \"josh\", \"kevin\", \"knife\", \"know\", \"know\", \"know\", \"know\", \"know\", \"laser\", \"laser\", \"lash\", \"lash\", \"lawyer\", \"layout\", \"lemon\", \"lemon\", \"lemon\", \"lemon\", \"les\", \"les\", \"les\", \"like\", \"like\", \"like\", \"like\", \"like\", \"lil\", \"little\", \"little\", \"little\", \"little\", \"little\", \"location\", \"location\", \"location\", \"location\", \"location\", \"look\", \"look\", \"look\", \"look\", \"look\", \"lot\", \"lot\", \"lot\", \"lot\", \"lot\", \"love\", \"love\", \"love\", \"love\", \"love\", \"lox\", \"macaron\", \"mais\", \"mais\", \"manicure\", \"manicure\", \"manicure\", \"manicure\", \"manicure\", \"margarita\", \"margarita\", \"margaritas\", \"margaritas\", \"maze\", \"meat\", \"meat\", \"meat\", \"meat\", \"meat\", \"mechanic\", \"mechanic\", \"mechanic\", \"medicine\", \"menu\", \"menu\", \"menu\", \"menu\", \"menu\", \"mex\", \"mex\", \"mince\", \"minute\", \"minute\", \"minute\", \"minute\", \"minute\", \"mojito\", \"mongolian\", \"mongolian\", \"month\", \"month\", \"month\", \"month\", \"month\", \"mortgage\", \"nacho\", \"nacho\", \"nail\", \"nail\", \"nail\", \"nail\", \"nail\", \"navigation\", \"need\", \"need\", \"need\", \"need\", \"need\", \"new\", \"new\", \"new\", \"new\", \"new\", \"nice\", \"nice\", \"nice\", \"nice\", \"nice\", \"nite\", \"noodle\", \"noodle\", \"noodle\", \"noodle\", \"noodle\", \"nordstrom\", \"office\", \"office\", \"office\", \"office\", \"office\", \"officially\", \"omelet\", \"order\", \"order\", \"order\", \"order\", \"order\", \"owe\", \"owe\", \"pad\", \"pad\", \"pad\", \"pad\", \"pad\", \"pakora\", \"patient\", \"patient\", \"patient\", \"patient\", \"patient\", \"pay\", \"pay\", \"pay\", \"pay\", \"pay\", \"pearl\", \"pedicure\", \"pedicure\", \"pedicure\", \"pedicure\", \"people\", \"people\", \"people\", \"people\", \"people\", \"peoria\", \"perspective\", \"pest\", \"pest\", \"pet\", \"pet\", \"pet\", \"pet\", \"pet\", \"pharmacy\", \"pharmacy\", \"pho\", \"pho\", \"pho\", \"pho\", \"pho\", \"phone\", \"phone\", \"phone\", \"phone\", \"phone\", \"photography\", \"photography\", \"physician\", \"pico\", \"pico\", \"pinball\", \"piss\", \"place\", \"place\", \"place\", \"place\", \"place\", \"ponzu\", \"pool\", \"pool\", \"pool\", \"pool\", \"pool\", \"pork\", \"pork\", \"pork\", \"pork\", \"pork\", \"pour\", \"pour\", \"pour\", \"pour\", \"pour\", \"poutine\", \"poutine\", \"poutine\", \"poutine\", \"pregnancy\", \"pregnant\", \"pregnant\", \"price\", \"price\", \"price\", \"price\", \"price\", \"procedure\", \"procedure\", \"procedure\", \"procedure\", \"professional\", \"professional\", \"professional\", \"professional\", \"professional\", \"professionally\", \"professionally\", \"promotion\", \"pudding\", \"pudding\", \"pudding\", \"pudding\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"purchase\", \"quesadilla\", \"quesadilla\", \"quick\", \"quick\", \"quick\", \"quick\", \"quick\", \"quit\", \"quit\", \"raman\", \"raman\", \"raman\", \"raman\", \"raman\", \"reality\", \"recline\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"recommend\", \"refill\", \"refill\", \"refill\", \"refill\", \"refill\", \"rep\", \"rep\", \"rep\", \"repair\", \"repair\", \"repair\", \"repair\", \"repair\", \"restaurant\", \"restaurant\", \"restaurant\", \"restaurant\", \"restaurant\", \"resume\", \"review\", \"review\", \"review\", \"review\", \"review\", \"rib\", \"rib\", \"rib\", \"rib\", \"rib\", \"rick\", \"rim\", \"rise\", \"roll\", \"roll\", \"roll\", \"roll\", \"roll\", \"room\", \"room\", \"room\", \"room\", \"room\", \"rubber\", \"rug\", \"rug\", \"rum\", \"running\", \"salad\", \"salad\", \"salad\", \"salad\", \"salad\", \"salon\", \"salon\", \"salon\", \"salon\", \"salon\", \"salsa\", \"salsa\", \"salsa\", \"salsa\", \"salsa\", \"sauce\", \"sauce\", \"sauce\", \"sauce\", \"sauce\", \"say\", \"say\", \"say\", \"say\", \"say\", \"schedule\", \"schedule\", \"schedule\", \"schedule\", \"schedule\", \"schwartz\", \"scorpion\", \"seat\", \"seat\", \"seat\", \"seat\", \"seat\", \"secure\", \"see\", \"see\", \"see\", \"see\", \"see\", \"server\", \"server\", \"server\", \"server\", \"server\", \"service\", \"service\", \"service\", \"service\", \"service\", \"shawarma\", \"shawarma\", \"shawarma\", \"ship\", \"shower\", \"shower\", \"shower\", \"shower\", \"shower\", \"silk\", \"sit\", \"sit\", \"sit\", \"sit\", \"sit\", \"skinny\", \"sleep\", \"sleep\", \"sleep\", \"sleep\", \"sleep\", \"smokey\", \"smokey\", \"sont\", \"sont\", \"soo\", \"soup\", \"soup\", \"soup\", \"soup\", \"soup\", \"specially\", \"spider\", \"staff\", \"staff\", \"staff\", \"staff\", \"staff\", \"star\", \"star\", \"star\", \"star\", \"star\", \"stay\", \"stay\", \"stay\", \"stay\", \"stay\", \"steak\", \"steak\", \"steak\", \"steak\", \"steak\", \"store\", \"store\", \"store\", \"store\", \"store\", \"stylist\", \"stylist\", \"stylist\", \"suite\", \"suite\", \"suite\", \"suite\", \"suite\", \"sum\", \"sum\", \"sum\", \"sum\", \"sum\", \"surgery\", \"surgery\", \"sushi\", \"sushi\", \"sushi\", \"sushi\", \"sushi\", \"table\", \"table\", \"table\", \"table\", \"table\", \"taco\", \"taco\", \"taco\", \"taco\", \"taco\", \"tai\", \"take\", \"take\", \"take\", \"take\", \"take\", \"talented\", \"talented\", \"tan\", \"tan\", \"tartar\", \"taste\", \"taste\", \"taste\", \"taste\", \"taste\", \"tasty\", \"tasty\", \"tasty\", \"tasty\", \"tasty\", \"tell\", \"tell\", \"tell\", \"tell\", \"tell\", \"tender\", \"tender\", \"tender\", \"tender\", \"tender\", \"test\", \"test\", \"test\", \"test\", \"test\", \"thai\", \"thai\", \"thai\", \"thai\", \"thai\", \"thing\", \"thing\", \"thing\", \"thing\", \"thing\", \"think\", \"think\", \"think\", \"think\", \"think\", \"tilapia\", \"time\", \"time\", \"time\", \"time\", \"time\", \"tip\", \"tip\", \"tip\", \"tip\", \"tip\", \"tire\", \"tire\", \"tire\", \"tire\", \"tire\", \"tissue\", \"tissue\", \"tops\", \"try\", \"try\", \"try\", \"try\", \"try\", \"tr\\u00e8s\", \"tr\\u00e8s\", \"und\", \"une\", \"une\", \"uneven\", \"unhappy\", \"unhappy\", \"unorganized\", \"uptown\", \"vehicle\", \"vehicle\", \"vehicle\", \"vehicle\", \"vehicle\", \"verify\", \"wait\", \"wait\", \"wait\", \"wait\", \"wait\", \"waiter\", \"waiter\", \"waiter\", \"waiter\", \"waiter\", \"waitress\", \"waitress\", \"waitress\", \"waitress\", \"waitress\", \"want\", \"want\", \"want\", \"want\", \"want\", \"warranty\", \"warranty\", \"warranty\", \"warranty\", \"wash\", \"wash\", \"wash\", \"wash\", \"wash\", \"way\", \"way\", \"way\", \"way\", \"way\", \"week\", \"week\", \"week\", \"week\", \"week\", \"weekly\", \"weekly\", \"weekly\", \"weekly\", \"weekly\", \"work\", \"work\", \"work\", \"work\", \"work\", \"year\", \"year\", \"year\", \"year\", \"year\", \"yellowtail\", \"yellowtail\", \"yoga\", \"yoga\", \"yoga\", \"yuk\", \"zucchini\", \"zucchini\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2, 3, 4, 5]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el35421404382511085609713984924\", ldavis_el35421404382511085609713984924_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el35421404382511085609713984924\", ldavis_el35421404382511085609713984924_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://cdnjs.cloudflare.com/ajax/libs/d3/3.5.5/d3.min.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.rawgit.com/bmabey/pyLDAvis/files/ldavis.v1.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el35421404382511085609713984924\", ldavis_el35421404382511085609713984924_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "0     -0.044363 -0.014928       1        1  32.200687\n",
              "1     -0.146230  0.014115       2        1  28.587732\n",
              "2      0.099133 -0.065177       3        1  21.054543\n",
              "3      0.001194 -0.021401       4        1  10.725058\n",
              "4      0.090266  0.087391       5        1   7.431980, topic_info=         Term         Freq        Total Category  logprob  loglift\n",
              "97       room  1045.000000  1045.000000  Default  30.0000  30.0000\n",
              "722       car   713.000000   713.000000  Default  29.0000  29.0000\n",
              "136      food  4799.000000  4799.000000  Default  28.0000  28.0000\n",
              "35       time  4151.000000  4151.000000  Default  27.0000  27.0000\n",
              "464      tell  1462.000000  1462.000000  Default  26.0000  26.0000\n",
              "..        ...          ...          ...      ...      ...      ...\n",
              "123     place   139.644079  5149.958810   Topic5  -5.5300  -1.0083\n",
              "464      tell    99.102049  1462.209326   Topic5  -5.8729  -0.0922\n",
              "41       good   121.902592  6274.434508   Topic5  -5.6659  -1.3416\n",
              "400  customer    87.627938  1095.013965   Topic5  -5.9960   0.0740\n",
              "136      food    94.637068  4799.613268   Topic5  -5.9190  -1.3269\n",
              "\n",
              "[473 rows x 6 columns], token_table=       Topic      Freq      Term\n",
              "term                            \n",
              "4294       5  0.932867      2006\n",
              "9365       2  0.928227      4.50\n",
              "3063       3  0.942838      a.m.\n",
              "4301       4  0.918399    accent\n",
              "6373       1  0.057577      alex\n",
              "...      ...       ...       ...\n",
              "7453       3  0.917320      yoga\n",
              "7453       4  0.053960      yoga\n",
              "11347      5  0.980563       yuk\n",
              "1815       1  0.073803  zucchini\n",
              "1815       2  0.910237  zucchini\n",
              "\n",
              "[1156 rows x 3 columns], R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2, 3, 4, 5])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# import seaborn as sns\n",
        "# import matplotlib.pyplot as plt\n",
        "# # Use pyLDAvis (or a ploting tool of your choice) to visualize your results \n",
        "\n",
        "# import pyLDAvis.gensim\n",
        "# # Visualize the topics\n",
        "# pyLDAvis.enable_notebook()\n",
        "# vis = pyLDAvis.gensim.prepare(lda, corpus, id2word)\n",
        "# vis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "words = [re.findall(r'\"([^\"]*)\"', t[1]) for t in lda.print_topics()]\n",
        "topics = [' '.join(t[0:5]) for t in words]\n",
        "\n",
        "for id, t in enumerate(topics):\n",
        "  print(f\"----- Topic {id} -----\")\n",
        "  print(t, end=\"\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBDSx_fiNIU6",
        "outputId": "395f2f99-e0d2-4786-99cd-ff813cbc91f0"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- Topic 0 -----\n",
            "food good place great order\n",
            "\n",
            "----- Topic 1 -----\n",
            "good place food like great\n",
            "\n",
            "----- Topic 2 -----\n",
            "time work like service tell\n",
            "\n",
            "----- Topic 3 -----\n",
            "time place come great good\n",
            "\n",
            "----- Topic 4 -----\n",
            "room hotel get service come\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "nbgrader": {
          "cell_type": "markdown",
          "checksum": "f44a26c754500ff0bf585296075bf754",
          "grade": false,
          "grade_id": "cell-bf9e63d9645bba84",
          "locked": true,
          "points": 0,
          "schema_version": 3,
          "solution": false,
          "task": true
        },
        "id": "UPc8z-f78YXM"
      },
      "source": [
        "#### 3. In markdown, write 1-2 paragraphs of analysis on the results of your topic model"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "u4-s1-nlp"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "nteract": {
      "version": "0.15.0"
    },
    "toc-autonumbering": false,
    "colab": {
      "name": "FLEX LS_DS_415_Sprint_Challenge_1_AG.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}